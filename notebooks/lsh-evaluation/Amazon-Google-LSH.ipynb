{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'Amazon-Google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.12755906,  0.20850394, -0.18645669, -0.03307087, -0.02834646,\n",
      "        -0.00125984,  0.03023622,  0.23244094, -0.06488189,  0.08724409],\n",
      "       [-0.14312153, -0.03562616, -0.10934608,  0.15376311,  0.0442628 ,\n",
      "        -0.08482418,  0.04333745,  0.12152992, -0.15175817, -0.1124306 ],\n",
      "       [-0.04335466, -0.03861644, -0.08268183,  0.21013978, -0.05875385,\n",
      "         0.17910448, -0.01066098, -0.13219616,  0.01445155, -0.23004027],\n",
      "       [ 0.12727585, -0.13655101, -0.03211955,  0.09498454, -0.06664377,\n",
      "         0.07488835, -0.0223291 ,  0.14943318,  0.1580213 , -0.13775335],\n",
      "       [ 0.10845516, -0.13275385,  0.17483208, -0.04583169, -0.06440142,\n",
      "        -0.17641249, -0.01639668,  0.15428684,  0.01916239, -0.1074674 ]]), array([[-0.21074933,  0.07136485, -0.02988403, -0.15789474, -0.1382694 ,\n",
      "        -0.02520071, -0.08318466, -0.12466548, -0.03925067, -0.11953613],\n",
      "       [ 0.01567091, -0.02840353, -0.13883448,  0.09402547, -0.13761019,\n",
      "        -0.16062684, -0.23922625,  0.08006856, -0.00097943,  0.10455436],\n",
      "       [ 0.10878226, -0.11259311,  0.13719037,  0.07950805, -0.0850511 ,\n",
      "         0.12939546, -0.00727525,  0.05733587, -0.14290663,  0.13996189],\n",
      "       [-0.01695692, -0.00206233, -0.17461045, -0.14505041, -0.04972502,\n",
      "        -0.03414299, -0.1083868 , -0.17598533,  0.22662695, -0.0664528 ],\n",
      "       [-0.18290258, -0.05301524, -0.15484869,  0.06096753,  0.16920698,\n",
      "         0.02385686, -0.1261321 ,  0.04749282, -0.11464546,  0.06693174]])]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.5769230769230769\n",
      "K: 1, L: 2, Precision:0.9358974358974359\n",
      "K: 1, L: 3, Precision:0.9957264957264957\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.4188034188034188\n",
      "K: 2, L: 2, Precision:0.7948717948717948\n",
      "K: 2, L: 3, Precision:0.9700854700854701\n",
      "K: 2, L: 4, Precision:0.9957264957264957\n",
      "K: 2, L: 5, Precision:1.0\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.2948717948717949\n",
      "K: 3, L: 2, Precision:0.6239316239316239\n",
      "K: 3, L: 3, Precision:0.8974358974358975\n",
      "K: 3, L: 4, Precision:0.9572649572649573\n",
      "K: 3, L: 5, Precision:0.9829059829059829\n",
      "K: 3, L: 6, Precision:1.0\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.2094017094017094\n",
      "K: 4, L: 2, Precision:0.5128205128205128\n",
      "K: 4, L: 3, Precision:0.6837606837606838\n",
      "K: 4, L: 4, Precision:0.8589743589743589\n",
      "K: 4, L: 5, Precision:0.8675213675213675\n",
      "K: 4, L: 6, Precision:0.9444444444444444\n",
      "K: 4, L: 7, Precision:0.9871794871794872\n",
      "K: 4, L: 8, Precision:0.9914529914529915\n",
      "K: 4, L: 9, Precision:0.9957264957264957\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.2222222222222222\n",
      "K: 5, L: 2, Precision:0.29914529914529914\n",
      "K: 5, L: 3, Precision:0.5085470085470085\n",
      "K: 5, L: 4, Precision:0.6837606837606838\n",
      "K: 5, L: 5, Precision:0.7905982905982906\n",
      "K: 5, L: 6, Precision:0.8888888888888888\n",
      "K: 5, L: 7, Precision:0.905982905982906\n",
      "K: 5, L: 8, Precision:0.9529914529914529\n",
      "K: 5, L: 9, Precision:0.9529914529914529\n",
      "K: 5, L: 10, Precision:0.9871794871794872\n",
      "K: 6, L: 1, Precision:0.07264957264957266\n",
      "K: 6, L: 2, Precision:0.2222222222222222\n",
      "K: 6, L: 3, Precision:0.358974358974359\n",
      "K: 6, L: 4, Precision:0.49145299145299143\n",
      "K: 6, L: 5, Precision:0.6068376068376068\n",
      "K: 6, L: 6, Precision:0.7222222222222222\n",
      "K: 6, L: 7, Precision:0.7564102564102564\n",
      "K: 6, L: 8, Precision:0.8034188034188035\n",
      "K: 6, L: 9, Precision:0.8675213675213675\n",
      "K: 6, L: 10, Precision:0.8760683760683761\n",
      "K: 7, L: 1, Precision:0.08547008547008547\n",
      "K: 7, L: 2, Precision:0.17094017094017094\n",
      "K: 7, L: 3, Precision:0.3247863247863248\n",
      "K: 7, L: 4, Precision:0.32051282051282054\n",
      "K: 7, L: 5, Precision:0.4658119658119658\n",
      "K: 7, L: 6, Precision:0.49572649572649574\n",
      "K: 7, L: 7, Precision:0.6111111111111112\n",
      "K: 7, L: 8, Precision:0.6282051282051282\n",
      "K: 7, L: 9, Precision:0.7222222222222222\n",
      "K: 7, L: 10, Precision:0.7051282051282052\n",
      "K: 8, L: 1, Precision:0.06837606837606838\n",
      "K: 8, L: 2, Precision:0.08547008547008547\n",
      "K: 8, L: 3, Precision:0.20512820512820512\n",
      "K: 8, L: 4, Precision:0.2606837606837607\n",
      "K: 8, L: 5, Precision:0.2863247863247863\n",
      "K: 8, L: 6, Precision:0.4017094017094017\n",
      "K: 8, L: 7, Precision:0.5384615384615384\n",
      "K: 8, L: 8, Precision:0.5128205128205128\n",
      "K: 8, L: 9, Precision:0.5470085470085471\n",
      "K: 8, L: 10, Precision:0.5470085470085471\n",
      "K: 9, L: 1, Precision:0.06837606837606838\n",
      "K: 9, L: 2, Precision:0.1282051282051282\n",
      "K: 9, L: 3, Precision:0.11965811965811966\n",
      "K: 9, L: 4, Precision:0.20085470085470086\n",
      "K: 9, L: 5, Precision:0.2222222222222222\n",
      "K: 9, L: 6, Precision:0.3162393162393162\n",
      "K: 9, L: 7, Precision:0.33760683760683763\n",
      "K: 9, L: 8, Precision:0.31196581196581197\n",
      "K: 9, L: 9, Precision:0.36752136752136755\n",
      "K: 9, L: 10, Precision:0.3888888888888889\n",
      "K: 10, L: 1, Precision:0.042735042735042736\n",
      "K: 10, L: 2, Precision:0.08974358974358974\n",
      "K: 10, L: 3, Precision:0.09401709401709402\n",
      "K: 10, L: 4, Precision:0.18803418803418803\n",
      "K: 10, L: 5, Precision:0.19658119658119658\n",
      "K: 10, L: 6, Precision:0.24786324786324787\n",
      "K: 10, L: 7, Precision:0.25213675213675213\n",
      "K: 10, L: 8, Precision:0.26495726495726496\n",
      "K: 10, L: 9, Precision:0.3076923076923077\n",
      "K: 10, L: 10, Precision:0.33760683760683763\n",
      "K: 11, L: 1, Precision:0.017094017094017096\n",
      "K: 11, L: 2, Precision:0.08547008547008547\n",
      "K: 11, L: 3, Precision:0.09829059829059829\n",
      "K: 11, L: 4, Precision:0.07264957264957266\n",
      "K: 11, L: 5, Precision:0.09401709401709402\n",
      "K: 11, L: 6, Precision:0.16666666666666666\n",
      "K: 11, L: 7, Precision:0.2222222222222222\n",
      "K: 11, L: 8, Precision:0.20085470085470086\n",
      "K: 11, L: 9, Precision:0.24358974358974358\n",
      "K: 11, L: 10, Precision:0.2264957264957265\n",
      "K: 12, L: 1, Precision:0.02564102564102564\n",
      "K: 12, L: 2, Precision:0.021367521367521368\n",
      "K: 12, L: 3, Precision:0.05982905982905983\n",
      "K: 12, L: 4, Precision:0.06837606837606838\n",
      "K: 12, L: 5, Precision:0.04700854700854701\n",
      "K: 12, L: 6, Precision:0.13247863247863248\n",
      "K: 12, L: 7, Precision:0.1282051282051282\n",
      "K: 12, L: 8, Precision:0.1581196581196581\n",
      "K: 12, L: 9, Precision:0.18376068376068377\n",
      "K: 12, L: 10, Precision:0.18376068376068377\n",
      "K: 13, L: 1, Precision:0.017094017094017096\n",
      "K: 13, L: 2, Precision:0.04700854700854701\n",
      "K: 13, L: 3, Precision:0.04700854700854701\n",
      "K: 13, L: 4, Precision:0.05555555555555555\n",
      "K: 13, L: 5, Precision:0.08547008547008547\n",
      "K: 13, L: 6, Precision:0.0811965811965812\n",
      "K: 13, L: 7, Precision:0.1111111111111111\n",
      "K: 13, L: 8, Precision:0.1111111111111111\n",
      "K: 13, L: 9, Precision:0.14957264957264957\n",
      "K: 13, L: 10, Precision:0.1282051282051282\n",
      "K: 14, L: 1, Precision:0.008547008547008548\n",
      "K: 14, L: 2, Precision:0.017094017094017096\n",
      "K: 14, L: 3, Precision:0.038461538461538464\n",
      "K: 14, L: 4, Precision:0.021367521367521368\n",
      "K: 14, L: 5, Precision:0.07692307692307693\n",
      "K: 14, L: 6, Precision:0.08547008547008547\n",
      "K: 14, L: 7, Precision:0.08547008547008547\n",
      "K: 14, L: 8, Precision:0.11965811965811966\n",
      "K: 14, L: 9, Precision:0.12393162393162394\n",
      "K: 14, L: 10, Precision:0.09401709401709402\n",
      "K: 15, L: 1, Precision:0.008547008547008548\n",
      "K: 15, L: 2, Precision:0.021367521367521368\n",
      "K: 15, L: 3, Precision:0.042735042735042736\n",
      "K: 15, L: 4, Precision:0.021367521367521368\n",
      "K: 15, L: 5, Precision:0.042735042735042736\n",
      "K: 15, L: 6, Precision:0.07264957264957266\n",
      "K: 15, L: 7, Precision:0.06837606837606838\n",
      "K: 15, L: 8, Precision:0.0811965811965812\n",
      "K: 15, L: 9, Precision:0.11538461538461539\n",
      "K: 15, L: 10, Precision:0.09401709401709402\n",
      "K: 16, L: 1, Precision:0.01282051282051282\n",
      "K: 16, L: 2, Precision:0.042735042735042736\n",
      "K: 16, L: 3, Precision:0.05128205128205128\n",
      "K: 16, L: 4, Precision:0.021367521367521368\n",
      "K: 16, L: 5, Precision:0.05555555555555555\n",
      "K: 16, L: 6, Precision:0.05555555555555555\n",
      "K: 16, L: 7, Precision:0.0641025641025641\n",
      "K: 16, L: 8, Precision:0.05128205128205128\n",
      "K: 16, L: 9, Precision:0.0641025641025641\n",
      "K: 16, L: 10, Precision:0.04700854700854701\n",
      "K: 17, L: 1, Precision:0.004273504273504274\n",
      "K: 17, L: 2, Precision:0.008547008547008548\n",
      "K: 17, L: 3, Precision:0.01282051282051282\n",
      "K: 17, L: 4, Precision:0.021367521367521368\n",
      "K: 17, L: 5, Precision:0.038461538461538464\n",
      "K: 17, L: 6, Precision:0.03418803418803419\n",
      "K: 17, L: 7, Precision:0.06837606837606838\n",
      "K: 17, L: 8, Precision:0.0641025641025641\n",
      "K: 17, L: 9, Precision:0.04700854700854701\n",
      "K: 17, L: 10, Precision:0.06837606837606838\n",
      "K: 18, L: 1, Precision:0.004273504273504274\n",
      "K: 18, L: 2, Precision:0.004273504273504274\n",
      "K: 18, L: 3, Precision:0.029914529914529916\n",
      "K: 18, L: 4, Precision:0.04700854700854701\n",
      "K: 18, L: 5, Precision:0.038461538461538464\n",
      "K: 18, L: 6, Precision:0.042735042735042736\n",
      "K: 18, L: 7, Precision:0.05128205128205128\n",
      "K: 18, L: 8, Precision:0.042735042735042736\n",
      "K: 18, L: 9, Precision:0.04700854700854701\n",
      "K: 18, L: 10, Precision:0.05128205128205128\n",
      "K: 19, L: 1, Precision:0.004273504273504274\n",
      "K: 19, L: 2, Precision:0.004273504273504274\n",
      "K: 19, L: 3, Precision:0.021367521367521368\n",
      "K: 19, L: 4, Precision:0.017094017094017096\n",
      "K: 19, L: 5, Precision:0.017094017094017096\n",
      "K: 19, L: 6, Precision:0.017094017094017096\n",
      "K: 19, L: 7, Precision:0.042735042735042736\n",
      "K: 19, L: 8, Precision:0.021367521367521368\n",
      "K: 19, L: 9, Precision:0.038461538461538464\n",
      "K: 19, L: 10, Precision:0.038461538461538464\n",
      "K: 20, L: 1, Precision:0.008547008547008548\n",
      "K: 20, L: 2, Precision:0.017094017094017096\n",
      "K: 20, L: 3, Precision:0.021367521367521368\n",
      "K: 20, L: 4, Precision:0.008547008547008548\n",
      "K: 20, L: 5, Precision:0.02564102564102564\n",
      "K: 20, L: 6, Precision:0.021367521367521368\n",
      "K: 20, L: 7, Precision:0.02564102564102564\n",
      "K: 20, L: 8, Precision:0.01282051282051282\n",
      "K: 20, L: 9, Precision:0.029914529914529916\n",
      "K: 20, L: 10, Precision:0.03418803418803419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 21, L: 1, Precision:0.0\n",
      "K: 21, L: 2, Precision:0.004273504273504274\n",
      "K: 21, L: 3, Precision:0.008547008547008548\n",
      "K: 21, L: 4, Precision:0.008547008547008548\n",
      "K: 21, L: 5, Precision:0.004273504273504274\n",
      "K: 21, L: 6, Precision:0.02564102564102564\n",
      "K: 21, L: 7, Precision:0.017094017094017096\n",
      "K: 21, L: 8, Precision:0.02564102564102564\n",
      "K: 21, L: 9, Precision:0.021367521367521368\n",
      "K: 21, L: 10, Precision:0.042735042735042736\n",
      "K: 22, L: 1, Precision:0.004273504273504274\n",
      "K: 22, L: 2, Precision:0.008547008547008548\n",
      "K: 22, L: 3, Precision:0.0\n",
      "K: 22, L: 4, Precision:0.017094017094017096\n",
      "K: 22, L: 5, Precision:0.01282051282051282\n",
      "K: 22, L: 6, Precision:0.021367521367521368\n",
      "K: 22, L: 7, Precision:0.02564102564102564\n",
      "K: 22, L: 8, Precision:0.01282051282051282\n",
      "K: 22, L: 9, Precision:0.03418803418803419\n",
      "K: 22, L: 10, Precision:0.038461538461538464\n",
      "K: 23, L: 1, Precision:0.0\n",
      "K: 23, L: 2, Precision:0.004273504273504274\n",
      "K: 23, L: 3, Precision:0.004273504273504274\n",
      "K: 23, L: 4, Precision:0.008547008547008548\n",
      "K: 23, L: 5, Precision:0.01282051282051282\n",
      "K: 23, L: 6, Precision:0.008547008547008548\n",
      "K: 23, L: 7, Precision:0.01282051282051282\n",
      "K: 23, L: 8, Precision:0.02564102564102564\n",
      "K: 23, L: 9, Precision:0.021367521367521368\n",
      "K: 23, L: 10, Precision:0.008547008547008548\n",
      "K: 24, L: 1, Precision:0.0\n",
      "K: 24, L: 2, Precision:0.0\n",
      "K: 24, L: 3, Precision:0.008547008547008548\n",
      "K: 24, L: 4, Precision:0.0\n",
      "K: 24, L: 5, Precision:0.004273504273504274\n",
      "K: 24, L: 6, Precision:0.004273504273504274\n",
      "K: 24, L: 7, Precision:0.01282051282051282\n",
      "K: 24, L: 8, Precision:0.017094017094017096\n",
      "K: 24, L: 9, Precision:0.017094017094017096\n",
      "K: 24, L: 10, Precision:0.029914529914529916\n",
      "K: 25, L: 1, Precision:0.01282051282051282\n",
      "K: 25, L: 2, Precision:0.004273504273504274\n",
      "K: 25, L: 3, Precision:0.004273504273504274\n",
      "K: 25, L: 4, Precision:0.0\n",
      "K: 25, L: 5, Precision:0.01282051282051282\n",
      "K: 25, L: 6, Precision:0.0\n",
      "K: 25, L: 7, Precision:0.0\n",
      "K: 25, L: 8, Precision:0.01282051282051282\n",
      "K: 25, L: 9, Precision:0.01282051282051282\n",
      "K: 25, L: 10, Precision:0.008547008547008548\n",
      "K: 26, L: 1, Precision:0.004273504273504274\n",
      "K: 26, L: 2, Precision:0.004273504273504274\n",
      "K: 26, L: 3, Precision:0.0\n",
      "K: 26, L: 4, Precision:0.004273504273504274\n",
      "K: 26, L: 5, Precision:0.004273504273504274\n",
      "K: 26, L: 6, Precision:0.008547008547008548\n",
      "K: 26, L: 7, Precision:0.008547008547008548\n",
      "K: 26, L: 8, Precision:0.021367521367521368\n",
      "K: 26, L: 9, Precision:0.008547008547008548\n",
      "K: 26, L: 10, Precision:0.021367521367521368\n",
      "K: 27, L: 1, Precision:0.0\n",
      "K: 27, L: 2, Precision:0.004273504273504274\n",
      "K: 27, L: 3, Precision:0.01282051282051282\n",
      "K: 27, L: 4, Precision:0.004273504273504274\n",
      "K: 27, L: 5, Precision:0.0\n",
      "K: 27, L: 6, Precision:0.008547008547008548\n",
      "K: 27, L: 7, Precision:0.008547008547008548\n",
      "K: 27, L: 8, Precision:0.004273504273504274\n",
      "K: 27, L: 9, Precision:0.008547008547008548\n",
      "K: 27, L: 10, Precision:0.021367521367521368\n",
      "K: 28, L: 1, Precision:0.0\n",
      "K: 28, L: 2, Precision:0.0\n",
      "K: 28, L: 3, Precision:0.01282051282051282\n",
      "K: 28, L: 4, Precision:0.008547008547008548\n",
      "K: 28, L: 5, Precision:0.004273504273504274\n",
      "K: 28, L: 6, Precision:0.008547008547008548\n",
      "K: 28, L: 7, Precision:0.0\n",
      "K: 28, L: 8, Precision:0.0\n",
      "K: 28, L: 9, Precision:0.008547008547008548\n",
      "K: 28, L: 10, Precision:0.017094017094017096\n",
      "K: 29, L: 1, Precision:0.0\n",
      "K: 29, L: 2, Precision:0.0\n",
      "K: 29, L: 3, Precision:0.0\n",
      "K: 29, L: 4, Precision:0.004273504273504274\n",
      "K: 29, L: 5, Precision:0.004273504273504274\n",
      "K: 29, L: 6, Precision:0.004273504273504274\n",
      "K: 29, L: 7, Precision:0.01282051282051282\n",
      "K: 29, L: 8, Precision:0.017094017094017096\n",
      "K: 29, L: 9, Precision:0.0\n",
      "K: 29, L: 10, Precision:0.01282051282051282\n",
      "K: 30, L: 1, Precision:0.0\n",
      "K: 30, L: 2, Precision:0.008547008547008548\n",
      "K: 30, L: 3, Precision:0.0\n",
      "K: 30, L: 4, Precision:0.004273504273504274\n",
      "K: 30, L: 5, Precision:0.0\n",
      "K: 30, L: 6, Precision:0.004273504273504274\n",
      "K: 30, L: 7, Precision:0.004273504273504274\n",
      "K: 30, L: 8, Precision:0.008547008547008548\n",
      "K: 30, L: 9, Precision:0.008547008547008548\n",
      "K: 30, L: 10, Precision:0.008547008547008548\n",
      "Max precision: 1.0, k: 4, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(30):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
