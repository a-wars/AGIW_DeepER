{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'Amazon-Google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.15167666,  0.00644015,  0.10393071, -0.16389074,  0.11214746,\n",
      "        -0.03131246,  0.17876971,  0.03042416,  0.12391739, -0.09749056],\n",
      "       [-0.18128079,  0.03842365,  0.1235468 ,  0.01044335,  0.18699507,\n",
      "         0.02246305,  0.07211823, -0.08866995, -0.14857143,  0.12748768],\n",
      "       [ 0.07494759,  0.1192348 , -0.08883648,  0.00602725, -0.01860587,\n",
      "        -0.24790356,  0.08018868, -0.24502096,  0.07311321,  0.04612159],\n",
      "       [-0.06517427, -0.01700198, -0.11561349,  0.04222159,  0.14735052,\n",
      "         0.04675545, -0.0034004 , -0.26268065, -0.24907906, -0.05072258],\n",
      "       [-0.08868759, -0.11986518,  0.07099221,  0.10427639, -0.09711397,\n",
      "        -0.19696651,  0.10722562, -0.11775858,  0.02106594, -0.07604803]]), array([[-0.1010929 , -0.14025501, -0.01930783,  0.1564663 ,  0.09763206,\n",
      "         0.04462659, -0.10637523,  0.15664845,  0.07723133, -0.1003643 ],\n",
      "       [-0.07303036, -0.19845207, -0.07402262,  0.19567374, -0.19071244,\n",
      "        -0.00297678, -0.06965668,  0.0571542 ,  0.06449692, -0.07382417],\n",
      "       [ 0.00767123, -0.20410959, -0.06410959,  0.08986301,  0.03616438,\n",
      "        -0.11287671, -0.12849315, -0.07863014, -0.19780822,  0.08027397],\n",
      "       [-0.01169471, -0.16844481,  0.15038982,  0.2016824 ,  0.14546574,\n",
      "         0.13890029,  0.06565449,  0.01928601,  0.09437833, -0.00410341],\n",
      "       [ 0.12549451,  0.16725275,  0.0410989 ,  0.12923077, -0.04703297,\n",
      "        -0.03208791,  0.15274725, -0.1032967 , -0.11274725, -0.08901099]])]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.9316239316239316\n",
      "K: 1, L: 2, Precision:0.8888888888888888\n",
      "K: 1, L: 3, Precision:0.9957264957264957\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.5384615384615384\n",
      "K: 2, L: 2, Precision:0.8803418803418803\n",
      "K: 2, L: 3, Precision:0.9529914529914529\n",
      "K: 2, L: 4, Precision:0.9829059829059829\n",
      "K: 2, L: 5, Precision:0.9957264957264957\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.3974358974358974\n",
      "K: 3, L: 2, Precision:0.6239316239316239\n",
      "K: 3, L: 3, Precision:0.8205128205128205\n",
      "K: 3, L: 4, Precision:0.905982905982906\n",
      "K: 3, L: 5, Precision:0.9829059829059829\n",
      "K: 3, L: 6, Precision:0.9957264957264957\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.23076923076923078\n",
      "K: 4, L: 2, Precision:0.49145299145299143\n",
      "K: 4, L: 3, Precision:0.688034188034188\n",
      "K: 4, L: 4, Precision:0.8076923076923077\n",
      "K: 4, L: 5, Precision:0.9017094017094017\n",
      "K: 4, L: 6, Precision:0.9487179487179487\n",
      "K: 4, L: 7, Precision:0.9829059829059829\n",
      "K: 4, L: 8, Precision:0.9914529914529915\n",
      "K: 4, L: 9, Precision:0.9957264957264957\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.13247863247863248\n",
      "K: 5, L: 2, Precision:0.32905982905982906\n",
      "K: 5, L: 3, Precision:0.5726495726495726\n",
      "K: 5, L: 4, Precision:0.6837606837606838\n",
      "K: 5, L: 5, Precision:0.8034188034188035\n",
      "K: 5, L: 6, Precision:0.8290598290598291\n",
      "K: 5, L: 7, Precision:0.905982905982906\n",
      "K: 5, L: 8, Precision:0.9444444444444444\n",
      "K: 5, L: 9, Precision:0.9786324786324786\n",
      "K: 5, L: 10, Precision:0.9914529914529915\n",
      "K: 6, L: 1, Precision:0.13675213675213677\n",
      "K: 6, L: 2, Precision:0.23076923076923078\n",
      "K: 6, L: 3, Precision:0.34615384615384615\n",
      "K: 6, L: 4, Precision:0.47863247863247865\n",
      "K: 6, L: 5, Precision:0.5982905982905983\n",
      "K: 6, L: 6, Precision:0.717948717948718\n",
      "K: 6, L: 7, Precision:0.7564102564102564\n",
      "K: 6, L: 8, Precision:0.8034188034188035\n",
      "K: 6, L: 9, Precision:0.8376068376068376\n",
      "K: 6, L: 10, Precision:0.9273504273504274\n",
      "K: 7, L: 1, Precision:0.04700854700854701\n",
      "K: 7, L: 2, Precision:0.21794871794871795\n",
      "K: 7, L: 3, Precision:0.28205128205128205\n",
      "K: 7, L: 4, Precision:0.37606837606837606\n",
      "K: 7, L: 5, Precision:0.3888888888888889\n",
      "K: 7, L: 6, Precision:0.5170940170940171\n",
      "K: 7, L: 7, Precision:0.6239316239316239\n",
      "K: 7, L: 8, Precision:0.6923076923076923\n",
      "K: 7, L: 9, Precision:0.6965811965811965\n",
      "K: 7, L: 10, Precision:0.7521367521367521\n",
      "K: 8, L: 1, Precision:0.09829059829059829\n",
      "K: 8, L: 2, Precision:0.1623931623931624\n",
      "K: 8, L: 3, Precision:0.19658119658119658\n",
      "K: 8, L: 4, Precision:0.2905982905982906\n",
      "K: 8, L: 5, Precision:0.3247863247863248\n",
      "K: 8, L: 6, Precision:0.3888888888888889\n",
      "K: 8, L: 7, Precision:0.46153846153846156\n",
      "K: 8, L: 8, Precision:0.4444444444444444\n",
      "K: 8, L: 9, Precision:0.5256410256410257\n",
      "K: 8, L: 10, Precision:0.594017094017094\n",
      "K: 9, L: 1, Precision:0.04700854700854701\n",
      "K: 9, L: 2, Precision:0.09401709401709402\n",
      "K: 9, L: 3, Precision:0.14102564102564102\n",
      "K: 9, L: 4, Precision:0.19230769230769232\n",
      "K: 9, L: 5, Precision:0.21794871794871795\n",
      "K: 9, L: 6, Precision:0.32905982905982906\n",
      "K: 9, L: 7, Precision:0.23504273504273504\n",
      "K: 9, L: 8, Precision:0.36324786324786323\n",
      "K: 9, L: 9, Precision:0.3974358974358974\n",
      "K: 9, L: 10, Precision:0.452991452991453\n",
      "K: 10, L: 1, Precision:0.05128205128205128\n",
      "K: 10, L: 2, Precision:0.05982905982905983\n",
      "K: 10, L: 3, Precision:0.11538461538461539\n",
      "K: 10, L: 4, Precision:0.10683760683760683\n",
      "K: 10, L: 5, Precision:0.16666666666666666\n",
      "K: 10, L: 6, Precision:0.21367521367521367\n",
      "K: 10, L: 7, Precision:0.3076923076923077\n",
      "K: 10, L: 8, Precision:0.24786324786324787\n",
      "K: 10, L: 9, Precision:0.32905982905982906\n",
      "K: 10, L: 10, Precision:0.3333333333333333\n",
      "Max precision: 1.0, k: 4, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(10):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
