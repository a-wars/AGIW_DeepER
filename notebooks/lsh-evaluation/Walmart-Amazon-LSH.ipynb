{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'Walmart-Amazon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.19327731,  0.01831502,  0.14522732,  0.05731523, -0.17259211,\n",
      "        -0.11118293, -0.13660849,  0.04072398, -0.00754148, -0.11721612],\n",
      "       [ 0.2074401 ,  0.00924758,  0.05128205,  0.20029424,  0.06872636,\n",
      "         0.17822615, -0.10508617,  0.15111391,  0.01240017, -0.01618327],\n",
      "       [-0.00770457, -0.03453773, -0.1761424 , -0.17747078, -0.01939426,\n",
      "        -0.14319872,  0.09750266, -0.15196599,  0.06137088, -0.13071201],\n",
      "       [-0.20827457,  0.14057358,  0.09261871, -0.00822755, -0.0025858 ,\n",
      "         0.13187588, -0.11777151,  0.13845792,  0.08439116,  0.07522332],\n",
      "       [ 0.06022053,  0.19083969, -0.00657337, -0.06806616,  0.10708227,\n",
      "        -0.09223919,  0.07633588, -0.20589483, -0.1331637 ,  0.05958439]]), array([[ 0.11617565, -0.13322216, -0.04891606,  0.06503613, -0.1372985 ,\n",
      "        -0.08986474, -0.13303687, -0.03872522,  0.09653511, -0.14118955],\n",
      "       [ 0.12780685,  0.03275367,  0.14114469, -0.12443019, -0.06061118,\n",
      "        -0.10568968, -0.07226068, -0.10467668,  0.16765153,  0.06297484],\n",
      "       [ 0.12532569,  0.00755602, -0.09874935,  0.08233455,  0.14721209,\n",
      "         0.00521105, -0.10291819,  0.01954143, -0.23319437,  0.17795727],\n",
      "       [-0.06993622,  0.14229162,  0.01011656,  0.1202991 ,  0.12667693,\n",
      "         0.01143611,  0.11040246,  0.20694964, -0.16472399,  0.03716736],\n",
      "       [-0.09086789,  0.1194199 ,  0.13664174,  0.09245411, -0.07976433,\n",
      "         0.06163608, -0.07205982, -0.06662135,  0.1758441 , -0.10469069]])]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.6632124352331606\n",
      "K: 1, L: 2, Precision:0.9481865284974094\n",
      "K: 1, L: 3, Precision:1.0\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.6683937823834197\n",
      "K: 2, L: 2, Precision:0.9585492227979274\n",
      "K: 2, L: 3, Precision:0.9896373056994818\n",
      "K: 2, L: 4, Precision:0.9948186528497409\n",
      "K: 2, L: 5, Precision:1.0\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.5129533678756477\n",
      "K: 3, L: 2, Precision:0.8497409326424871\n",
      "K: 3, L: 3, Precision:0.9430051813471503\n",
      "K: 3, L: 4, Precision:0.9792746113989638\n",
      "K: 3, L: 5, Precision:0.9948186528497409\n",
      "K: 3, L: 6, Precision:1.0\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.40414507772020725\n",
      "K: 4, L: 2, Precision:0.5854922279792746\n",
      "K: 4, L: 3, Precision:0.8290155440414507\n",
      "K: 4, L: 4, Precision:0.9378238341968912\n",
      "K: 4, L: 5, Precision:0.9689119170984456\n",
      "K: 4, L: 6, Precision:1.0\n",
      "K: 4, L: 7, Precision:1.0\n",
      "K: 4, L: 8, Precision:1.0\n",
      "K: 4, L: 9, Precision:1.0\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.23316062176165803\n",
      "K: 5, L: 2, Precision:0.49740932642487046\n",
      "K: 5, L: 3, Precision:0.7202072538860104\n",
      "K: 5, L: 4, Precision:0.8704663212435233\n",
      "K: 5, L: 5, Precision:0.917098445595855\n",
      "K: 5, L: 6, Precision:0.9378238341968912\n",
      "K: 5, L: 7, Precision:0.9326424870466321\n",
      "K: 5, L: 8, Precision:0.9740932642487047\n",
      "K: 5, L: 9, Precision:0.9896373056994818\n",
      "K: 5, L: 10, Precision:0.9844559585492227\n",
      "K: 6, L: 1, Precision:0.21761658031088082\n",
      "K: 6, L: 2, Precision:0.3316062176165803\n",
      "K: 6, L: 3, Precision:0.5647668393782384\n",
      "K: 6, L: 4, Precision:0.6787564766839378\n",
      "K: 6, L: 5, Precision:0.7409326424870466\n",
      "K: 6, L: 6, Precision:0.8808290155440415\n",
      "K: 6, L: 7, Precision:0.9222797927461139\n",
      "K: 6, L: 8, Precision:0.927461139896373\n",
      "K: 6, L: 9, Precision:0.9481865284974094\n",
      "K: 6, L: 10, Precision:0.9637305699481865\n",
      "K: 7, L: 1, Precision:0.3005181347150259\n",
      "K: 7, L: 2, Precision:0.39378238341968913\n",
      "K: 7, L: 3, Precision:0.5595854922279793\n",
      "K: 7, L: 4, Precision:0.5958549222797928\n",
      "K: 7, L: 5, Precision:0.6735751295336787\n",
      "K: 7, L: 6, Precision:0.7150259067357513\n",
      "K: 7, L: 7, Precision:0.7150259067357513\n",
      "K: 7, L: 8, Precision:0.8341968911917098\n",
      "K: 7, L: 9, Precision:0.9067357512953368\n",
      "K: 7, L: 10, Precision:0.9119170984455959\n",
      "K: 8, L: 1, Precision:0.21761658031088082\n",
      "K: 8, L: 2, Precision:0.27979274611398963\n",
      "K: 8, L: 3, Precision:0.5181347150259067\n",
      "K: 8, L: 4, Precision:0.47150259067357514\n",
      "K: 8, L: 5, Precision:0.5906735751295337\n",
      "K: 8, L: 6, Precision:0.6424870466321243\n",
      "K: 8, L: 7, Precision:0.6735751295336787\n",
      "K: 8, L: 8, Precision:0.7668393782383419\n",
      "K: 8, L: 9, Precision:0.7979274611398963\n",
      "K: 8, L: 10, Precision:0.7823834196891192\n",
      "K: 9, L: 1, Precision:0.14507772020725387\n",
      "K: 9, L: 2, Precision:0.18652849740932642\n",
      "K: 9, L: 3, Precision:0.32124352331606215\n",
      "K: 9, L: 4, Precision:0.44559585492227977\n",
      "K: 9, L: 5, Precision:0.6217616580310881\n",
      "K: 9, L: 6, Precision:0.6217616580310881\n",
      "K: 9, L: 7, Precision:0.7202072538860104\n",
      "K: 9, L: 8, Precision:0.6787564766839378\n",
      "K: 9, L: 9, Precision:0.7409326424870466\n",
      "K: 9, L: 10, Precision:0.6994818652849741\n",
      "K: 10, L: 1, Precision:0.21761658031088082\n",
      "K: 10, L: 2, Precision:0.3316062176165803\n",
      "K: 10, L: 3, Precision:0.27979274611398963\n",
      "K: 10, L: 4, Precision:0.40414507772020725\n",
      "K: 10, L: 5, Precision:0.38341968911917096\n",
      "K: 10, L: 6, Precision:0.40414507772020725\n",
      "K: 10, L: 7, Precision:0.5492227979274611\n",
      "K: 10, L: 8, Precision:0.6010362694300518\n",
      "K: 10, L: 9, Precision:0.538860103626943\n",
      "K: 10, L: 10, Precision:0.6010362694300518\n",
      "Max precision: 1.0, k: 4, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(10):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
