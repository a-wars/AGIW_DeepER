{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'DBLP-Scholar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.13545009, -0.07971626,  0.10099645,  0.08951191,  0.15098801,\n",
      "         0.1405168 , -0.07481844, -0.06840061, -0.06755616, -0.09204526],\n",
      "       [ 0.0177497 ,  0.13929001,  0.29482551, -0.03880866,  0.03188929,\n",
      "         0.19253911,  0.06498195,  0.03459687,  0.13628159,  0.0490373 ],\n",
      "       [-0.03739612, -0.20803324,  0.08919668,  0.08116343,  0.01080332,\n",
      "         0.09584488, -0.18975069,  0.21440443, -0.02742382,  0.04598338],\n",
      "       [ 0.15810355, -0.02757389, -0.18706606, -0.17377504,  0.02241619,\n",
      "         0.1674271 ,  0.05137869, -0.06744694, -0.13667923,  0.00813331],\n",
      "       [-0.01095836,  0.11097828, -0.18549512,  0.15501096, -0.08607292,\n",
      "         0.09085475, -0.08408049, -0.16855947, -0.06814106, -0.03984858]]), array([[ 0.03017329, -0.02568807,  0.06055046, -0.2038736 , -0.11437309,\n",
      "         0.16330275,  0.1412844 ,  0.00713558, -0.1420999 ,  0.11151886],\n",
      "       [-0.05588311, -0.01691874,  0.21148423, -0.08613176,  0.05229428,\n",
      "         0.06998206,  0.13201743, -0.06895668,  0.09715458,  0.20917713],\n",
      "       [-0.0959651 , -0.13813159, -0.10305344, -0.10305344, -0.02290076,\n",
      "        -0.12231916, -0.11541258,  0.08705925, -0.05743366, -0.15467103],\n",
      "       [-0.00655282, -0.19221604, -0.05798253, -0.06771247, -0.05341541,\n",
      "         0.12867355,  0.08975377,  0.13046068,  0.09948372,  0.17374901],\n",
      "       [ 0.08774862, -0.05348487, -0.0315895 , -0.1582818 , -0.10061842,\n",
      "         0.0864115 , -0.10312552, -0.15895036,  0.11332108,  0.10646833]])]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.7700934579439253\n",
      "K: 1, L: 2, Precision:0.9719626168224299\n",
      "K: 1, L: 3, Precision:1.0\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.7560747663551401\n",
      "K: 2, L: 2, Precision:0.9046728971962616\n",
      "K: 2, L: 3, Precision:0.983177570093458\n",
      "K: 2, L: 4, Precision:0.9990654205607477\n",
      "K: 2, L: 5, Precision:0.9990654205607477\n",
      "K: 2, L: 6, Precision:0.9990654205607477\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.5242990654205607\n",
      "K: 3, L: 2, Precision:0.8074766355140187\n",
      "K: 3, L: 3, Precision:0.9429906542056075\n",
      "K: 3, L: 4, Precision:0.9728971962616823\n",
      "K: 3, L: 5, Precision:0.9925233644859813\n",
      "K: 3, L: 6, Precision:0.9981308411214953\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.3616822429906542\n",
      "K: 4, L: 2, Precision:0.6523364485981309\n",
      "K: 4, L: 3, Precision:0.8102803738317756\n",
      "K: 4, L: 4, Precision:0.908411214953271\n",
      "K: 4, L: 5, Precision:0.9682242990654205\n",
      "K: 4, L: 6, Precision:0.994392523364486\n",
      "K: 4, L: 7, Precision:0.9887850467289719\n",
      "K: 4, L: 8, Precision:0.9990654205607477\n",
      "K: 4, L: 9, Precision:0.9990654205607477\n",
      "K: 4, L: 10, Precision:0.9990654205607477\n",
      "K: 5, L: 1, Precision:0.3018691588785047\n",
      "K: 5, L: 2, Precision:0.5626168224299065\n",
      "K: 5, L: 3, Precision:0.688785046728972\n",
      "K: 5, L: 4, Precision:0.8252336448598131\n",
      "K: 5, L: 5, Precision:0.883177570093458\n",
      "K: 5, L: 6, Precision:0.9214953271028037\n",
      "K: 5, L: 7, Precision:0.9607476635514018\n",
      "K: 5, L: 8, Precision:0.9719626168224299\n",
      "K: 5, L: 9, Precision:0.9813084112149533\n",
      "K: 5, L: 10, Precision:0.997196261682243\n",
      "K: 6, L: 1, Precision:0.33738317757009345\n",
      "K: 6, L: 2, Precision:0.4738317757009346\n",
      "K: 6, L: 3, Precision:0.6644859813084112\n",
      "K: 6, L: 4, Precision:0.7626168224299066\n",
      "K: 6, L: 5, Precision:0.8\n",
      "K: 6, L: 6, Precision:0.8121495327102803\n",
      "K: 6, L: 7, Precision:0.9102803738317757\n",
      "K: 6, L: 8, Precision:0.9364485981308411\n",
      "K: 6, L: 9, Precision:0.9710280373831776\n",
      "K: 6, L: 10, Precision:0.9785046728971962\n",
      "K: 7, L: 1, Precision:0.21401869158878506\n",
      "K: 7, L: 2, Precision:0.42990654205607476\n",
      "K: 7, L: 3, Precision:0.5514018691588785\n",
      "K: 7, L: 4, Precision:0.5719626168224299\n",
      "K: 7, L: 5, Precision:0.7336448598130841\n",
      "K: 7, L: 6, Precision:0.8308411214953271\n",
      "K: 7, L: 7, Precision:0.794392523364486\n",
      "K: 7, L: 8, Precision:0.8700934579439252\n",
      "K: 7, L: 9, Precision:0.8878504672897196\n",
      "K: 7, L: 10, Precision:0.9102803738317757\n",
      "K: 8, L: 1, Precision:0.18785046728971963\n",
      "K: 8, L: 2, Precision:0.36822429906542054\n",
      "K: 8, L: 3, Precision:0.41869158878504675\n",
      "K: 8, L: 4, Precision:0.5663551401869159\n",
      "K: 8, L: 5, Precision:0.5990654205607476\n",
      "K: 8, L: 6, Precision:0.6925233644859813\n",
      "K: 8, L: 7, Precision:0.7616822429906542\n",
      "K: 8, L: 8, Precision:0.7485981308411215\n",
      "K: 8, L: 9, Precision:0.7906542056074767\n",
      "K: 8, L: 10, Precision:0.8037383177570093\n",
      "K: 9, L: 1, Precision:0.17476635514018693\n",
      "K: 9, L: 2, Precision:0.30934579439252335\n",
      "K: 9, L: 3, Precision:0.402803738317757\n",
      "K: 9, L: 4, Precision:0.4803738317757009\n",
      "K: 9, L: 5, Precision:0.5504672897196262\n",
      "K: 9, L: 6, Precision:0.5990654205607476\n",
      "K: 9, L: 7, Precision:0.6261682242990654\n",
      "K: 9, L: 8, Precision:0.7102803738317757\n",
      "K: 9, L: 9, Precision:0.711214953271028\n",
      "K: 9, L: 10, Precision:0.7457943925233644\n",
      "K: 10, L: 1, Precision:0.14766355140186915\n",
      "K: 10, L: 2, Precision:0.24205607476635513\n",
      "K: 10, L: 3, Precision:0.4046728971962617\n",
      "K: 10, L: 4, Precision:0.3710280373831776\n",
      "K: 10, L: 5, Precision:0.49065420560747663\n",
      "K: 10, L: 6, Precision:0.5289719626168224\n",
      "K: 10, L: 7, Precision:0.5682242990654206\n",
      "K: 10, L: 8, Precision:0.6327102803738318\n",
      "K: 10, L: 9, Precision:0.6467289719626168\n",
      "K: 10, L: 10, Precision:0.6906542056074766\n",
      "Max precision: 1.0, k: 3, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(10):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
