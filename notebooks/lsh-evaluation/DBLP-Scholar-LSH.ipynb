{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'DBLP-Scholar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.02130077, -0.01306447,  0.16074979,  0.04089747, -0.02953706,\n",
      "         0.16586197, -0.20704345, -0.05367793,  0.09883556,  0.20903153],\n",
      "       [ 0.14984148, -0.16302353, -0.07959286,  0.02069081, -0.09310863,\n",
      "        -0.12865009, -0.08660103,  0.12414484, -0.03437344,  0.1199733 ],\n",
      "       [ 0.16826004, -0.00979924, -0.16610899, -0.11185468,  0.01434034,\n",
      "        -0.00262906, -0.19765774, -0.1500956 ,  0.13790631,  0.04134799],\n",
      "       [-0.01925926,  0.16185185,  0.03296296, -0.17555556,  0.1087037 ,\n",
      "        -0.11351852,  0.03222222, -0.08055556,  0.11277778, -0.16259259],\n",
      "       [-0.17319007, -0.02532617, -0.08007163,  0.03811717, -0.04783832,\n",
      "         0.10079304,  0.22640061, -0.12023535,  0.01202354,  0.17600409]]), array([[ 0.02269101,  0.16114164, -0.08810495, -0.06257756, -0.00407729,\n",
      "        -0.1145187 , -0.11398688,  0.10476866, -0.15865981,  0.1694735 ],\n",
      "       [-0.00179937,  0.05892937,  0.00382366, -0.19860549,  0.07804768,\n",
      "         0.06050382,  0.21322537, -0.14417454, -0.20535313, -0.03553756],\n",
      "       [-0.13859692,  0.01173307,  0.19432901,  0.0012222 ,  0.08530922,\n",
      "         0.13615253,  0.08213151, -0.05939868,  0.09924224, -0.19188462],\n",
      "       [-0.08862144,  0.16958425, -0.02133479,  0.09655361, -0.08971554,\n",
      "        -0.05032823, -0.06947484, -0.08561269, -0.14934354, -0.17943107],\n",
      "       [ 0.20835393,  0.09787444, -0.04102818, -0.18734553, -0.03336629,\n",
      "         0.10998517, -0.06154226,  0.13099357, -0.05462185,  0.07488878]])]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.7345794392523365\n",
      "K: 1, L: 2, Precision:0.974766355140187\n",
      "K: 1, L: 3, Precision:0.994392523364486\n",
      "K: 1, L: 4, Precision:0.9981308411214953\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.5317757009345795\n",
      "K: 2, L: 2, Precision:0.9196261682242991\n",
      "K: 2, L: 3, Precision:0.985981308411215\n",
      "K: 2, L: 4, Precision:0.9962616822429906\n",
      "K: 2, L: 5, Precision:0.9990654205607477\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.47757009345794393\n",
      "K: 3, L: 2, Precision:0.8084112149532711\n",
      "K: 3, L: 3, Precision:0.9345794392523364\n",
      "K: 3, L: 4, Precision:0.9813084112149533\n",
      "K: 3, L: 5, Precision:0.9906542056074766\n",
      "K: 3, L: 6, Precision:0.9990654205607477\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.3542056074766355\n",
      "K: 4, L: 2, Precision:0.6598130841121496\n",
      "K: 4, L: 3, Precision:0.8598130841121495\n",
      "K: 4, L: 4, Precision:0.9177570093457944\n",
      "K: 4, L: 5, Precision:0.9654205607476636\n",
      "K: 4, L: 6, Precision:0.9803738317757009\n",
      "K: 4, L: 7, Precision:0.997196261682243\n",
      "K: 4, L: 8, Precision:0.9990654205607477\n",
      "K: 4, L: 9, Precision:1.0\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.33084112149532713\n",
      "K: 5, L: 2, Precision:0.5766355140186916\n",
      "K: 5, L: 3, Precision:0.719626168224299\n",
      "K: 5, L: 4, Precision:0.791588785046729\n",
      "K: 5, L: 5, Precision:0.914018691588785\n",
      "K: 5, L: 6, Precision:0.9401869158878504\n",
      "K: 5, L: 7, Precision:0.9794392523364486\n",
      "K: 5, L: 8, Precision:0.9794392523364486\n",
      "K: 5, L: 9, Precision:0.994392523364486\n",
      "K: 5, L: 10, Precision:0.997196261682243\n",
      "K: 6, L: 1, Precision:0.42429906542056073\n",
      "K: 6, L: 2, Precision:0.4252336448598131\n",
      "K: 6, L: 3, Precision:0.5934579439252337\n",
      "K: 6, L: 4, Precision:0.7570093457943925\n",
      "K: 6, L: 5, Precision:0.802803738317757\n",
      "K: 6, L: 6, Precision:0.9009345794392524\n",
      "K: 6, L: 7, Precision:0.914018691588785\n",
      "K: 6, L: 8, Precision:0.9448598130841122\n",
      "K: 6, L: 9, Precision:0.9355140186915888\n",
      "K: 6, L: 10, Precision:0.9691588785046729\n",
      "K: 7, L: 1, Precision:0.3018691588785047\n",
      "K: 7, L: 2, Precision:0.34392523364485983\n",
      "K: 7, L: 3, Precision:0.5299065420560748\n",
      "K: 7, L: 4, Precision:0.6570093457943925\n",
      "K: 7, L: 5, Precision:0.7289719626168224\n",
      "K: 7, L: 6, Precision:0.7523364485981309\n",
      "K: 7, L: 7, Precision:0.8700934579439252\n",
      "K: 7, L: 8, Precision:0.883177570093458\n",
      "K: 7, L: 9, Precision:0.8700934579439252\n",
      "K: 7, L: 10, Precision:0.8962616822429906\n",
      "K: 8, L: 1, Precision:0.17943925233644858\n",
      "K: 8, L: 2, Precision:0.30934579439252335\n",
      "K: 8, L: 3, Precision:0.5242990654205607\n",
      "K: 8, L: 4, Precision:0.5560747663551402\n",
      "K: 8, L: 5, Precision:0.6271028037383177\n",
      "K: 8, L: 6, Precision:0.6308411214953271\n",
      "K: 8, L: 7, Precision:0.7542056074766356\n",
      "K: 8, L: 8, Precision:0.7878504672897196\n",
      "K: 8, L: 9, Precision:0.8420560747663551\n",
      "K: 8, L: 10, Precision:0.8364485981308412\n",
      "K: 9, L: 1, Precision:0.18878504672897195\n",
      "K: 9, L: 2, Precision:0.29626168224299065\n",
      "K: 9, L: 3, Precision:0.40186915887850466\n",
      "K: 9, L: 4, Precision:0.4934579439252336\n",
      "K: 9, L: 5, Precision:0.6140186915887851\n",
      "K: 9, L: 6, Precision:0.5785046728971963\n",
      "K: 9, L: 7, Precision:0.6336448598130842\n",
      "K: 9, L: 8, Precision:0.685981308411215\n",
      "K: 9, L: 9, Precision:0.7560747663551401\n",
      "K: 9, L: 10, Precision:0.7542056074766356\n",
      "K: 10, L: 1, Precision:0.15233644859813084\n",
      "K: 10, L: 2, Precision:0.23271028037383176\n",
      "K: 10, L: 3, Precision:0.3233644859813084\n",
      "K: 10, L: 4, Precision:0.42429906542056073\n",
      "K: 10, L: 5, Precision:0.4588785046728972\n",
      "K: 10, L: 6, Precision:0.5831775700934579\n",
      "K: 10, L: 7, Precision:0.6299065420560748\n",
      "K: 10, L: 8, Precision:0.6476635514018692\n",
      "K: 10, L: 9, Precision:0.7009345794392523\n",
      "K: 10, L: 10, Precision:0.6831775700934579\n",
      "K: 11, L: 1, Precision:0.15046728971962617\n",
      "K: 11, L: 2, Precision:0.18691588785046728\n",
      "K: 11, L: 3, Precision:0.3018691588785047\n",
      "K: 11, L: 4, Precision:0.3878504672897196\n",
      "K: 11, L: 5, Precision:0.37383177570093457\n",
      "K: 11, L: 6, Precision:0.45514018691588787\n",
      "K: 11, L: 7, Precision:0.5626168224299065\n",
      "K: 11, L: 8, Precision:0.5579439252336449\n",
      "K: 11, L: 9, Precision:0.5738317757009346\n",
      "K: 11, L: 10, Precision:0.6205607476635514\n",
      "K: 12, L: 1, Precision:0.11401869158878504\n",
      "K: 12, L: 2, Precision:0.17289719626168223\n",
      "K: 12, L: 3, Precision:0.29345794392523367\n",
      "K: 12, L: 4, Precision:0.2803738317757009\n",
      "K: 12, L: 5, Precision:0.37009345794392523\n",
      "K: 12, L: 6, Precision:0.46261682242990654\n",
      "K: 12, L: 7, Precision:0.4130841121495327\n",
      "K: 12, L: 8, Precision:0.5336448598130841\n",
      "K: 12, L: 9, Precision:0.508411214953271\n",
      "K: 12, L: 10, Precision:0.5429906542056074\n",
      "K: 13, L: 1, Precision:0.07570093457943926\n",
      "K: 13, L: 2, Precision:0.14205607476635515\n",
      "K: 13, L: 3, Precision:0.2588785046728972\n",
      "K: 13, L: 4, Precision:0.2644859813084112\n",
      "K: 13, L: 5, Precision:0.3252336448598131\n",
      "K: 13, L: 6, Precision:0.4261682242990654\n",
      "K: 13, L: 7, Precision:0.41962616822429905\n",
      "K: 13, L: 8, Precision:0.4439252336448598\n",
      "K: 13, L: 9, Precision:0.4663551401869159\n",
      "K: 13, L: 10, Precision:0.44953271028037384\n",
      "K: 14, L: 1, Precision:0.06822429906542056\n",
      "K: 14, L: 2, Precision:0.1542056074766355\n",
      "K: 14, L: 3, Precision:0.21401869158878506\n",
      "K: 14, L: 4, Precision:0.2588785046728972\n",
      "K: 14, L: 5, Precision:0.28598130841121494\n",
      "K: 14, L: 6, Precision:0.3401869158878505\n",
      "K: 14, L: 7, Precision:0.36822429906542054\n",
      "K: 14, L: 8, Precision:0.3850467289719626\n",
      "K: 14, L: 9, Precision:0.4\n",
      "K: 14, L: 10, Precision:0.4336448598130841\n",
      "K: 15, L: 1, Precision:0.09532710280373832\n",
      "K: 15, L: 2, Precision:0.12710280373831775\n",
      "K: 15, L: 3, Precision:0.18130841121495328\n",
      "K: 15, L: 4, Precision:0.26822429906542056\n",
      "K: 15, L: 5, Precision:0.2626168224299065\n",
      "K: 15, L: 6, Precision:0.2822429906542056\n",
      "K: 15, L: 7, Precision:0.3121495327102804\n",
      "K: 15, L: 8, Precision:0.4046728971962617\n",
      "K: 15, L: 9, Precision:0.3663551401869159\n",
      "K: 15, L: 10, Precision:0.3766355140186916\n",
      "K: 16, L: 1, Precision:0.04579439252336449\n",
      "K: 16, L: 2, Precision:0.11682242990654206\n",
      "K: 16, L: 3, Precision:0.13457943925233645\n",
      "K: 16, L: 4, Precision:0.2130841121495327\n",
      "K: 16, L: 5, Precision:0.22149532710280373\n",
      "K: 16, L: 6, Precision:0.24485981308411214\n",
      "K: 16, L: 7, Precision:0.2822429906542056\n",
      "K: 16, L: 8, Precision:0.33084112149532713\n",
      "K: 16, L: 9, Precision:0.33084112149532713\n",
      "K: 16, L: 10, Precision:0.3691588785046729\n",
      "K: 17, L: 1, Precision:0.0616822429906542\n",
      "K: 17, L: 2, Precision:0.08878504672897196\n",
      "K: 17, L: 3, Precision:0.13925233644859814\n",
      "K: 17, L: 4, Precision:0.16728971962616823\n",
      "K: 17, L: 5, Precision:0.20093457943925233\n",
      "K: 17, L: 6, Precision:0.27289719626168224\n",
      "K: 17, L: 7, Precision:0.22710280373831776\n",
      "K: 17, L: 8, Precision:0.2616822429906542\n",
      "K: 17, L: 9, Precision:0.29626168224299065\n",
      "K: 17, L: 10, Precision:0.30934579439252335\n",
      "K: 18, L: 1, Precision:0.027102803738317756\n",
      "K: 18, L: 2, Precision:0.07570093457943926\n",
      "K: 18, L: 3, Precision:0.09626168224299066\n",
      "K: 18, L: 4, Precision:0.1542056074766355\n",
      "K: 18, L: 5, Precision:0.21214953271028036\n",
      "K: 18, L: 6, Precision:0.18411214953271027\n",
      "K: 18, L: 7, Precision:0.22149532710280373\n",
      "K: 18, L: 8, Precision:0.25981308411214954\n",
      "K: 18, L: 9, Precision:0.2850467289719626\n",
      "K: 18, L: 10, Precision:0.29439252336448596\n",
      "K: 19, L: 1, Precision:0.03551401869158879\n",
      "K: 19, L: 2, Precision:0.09906542056074766\n",
      "K: 19, L: 3, Precision:0.1261682242990654\n",
      "K: 19, L: 4, Precision:0.1205607476635514\n",
      "K: 19, L: 5, Precision:0.15981308411214953\n",
      "K: 19, L: 6, Precision:0.15981308411214953\n",
      "K: 19, L: 7, Precision:0.18130841121495328\n",
      "K: 19, L: 8, Precision:0.16728971962616823\n",
      "K: 19, L: 9, Precision:0.2504672897196262\n",
      "K: 19, L: 10, Precision:0.26822429906542056\n",
      "K: 20, L: 1, Precision:0.041121495327102804\n",
      "K: 20, L: 2, Precision:0.05514018691588785\n",
      "K: 20, L: 3, Precision:0.09158878504672897\n",
      "K: 20, L: 4, Precision:0.13551401869158877\n",
      "K: 20, L: 5, Precision:0.1411214953271028\n",
      "K: 20, L: 6, Precision:0.13457943925233645\n",
      "K: 20, L: 7, Precision:0.18411214953271027\n",
      "K: 20, L: 8, Precision:0.2\n",
      "K: 20, L: 9, Precision:0.21682242990654205\n",
      "K: 20, L: 10, Precision:0.23738317757009345\n",
      "K: 21, L: 1, Precision:0.02149532710280374\n",
      "K: 21, L: 2, Precision:0.052336448598130844\n",
      "K: 21, L: 3, Precision:0.08785046728971962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 21, L: 4, Precision:0.1102803738317757\n",
      "K: 21, L: 5, Precision:0.12429906542056075\n",
      "K: 21, L: 6, Precision:0.12242990654205607\n",
      "K: 21, L: 7, Precision:0.1542056074766355\n",
      "K: 21, L: 8, Precision:0.17570093457943925\n",
      "K: 21, L: 9, Precision:0.17757009345794392\n",
      "K: 21, L: 10, Precision:0.197196261682243\n",
      "K: 22, L: 1, Precision:0.014953271028037384\n",
      "K: 22, L: 2, Precision:0.044859813084112146\n",
      "K: 22, L: 3, Precision:0.07102803738317758\n",
      "K: 22, L: 4, Precision:0.1102803738317757\n",
      "K: 22, L: 5, Precision:0.10841121495327102\n",
      "K: 22, L: 6, Precision:0.15233644859813084\n",
      "K: 22, L: 7, Precision:0.11214953271028037\n",
      "K: 22, L: 8, Precision:0.16355140186915887\n",
      "K: 22, L: 9, Precision:0.17570093457943925\n",
      "K: 22, L: 10, Precision:0.19906542056074766\n",
      "K: 23, L: 1, Precision:0.018691588785046728\n",
      "K: 23, L: 2, Precision:0.037383177570093455\n",
      "K: 23, L: 3, Precision:0.06822429906542056\n",
      "K: 23, L: 4, Precision:0.09158878504672897\n",
      "K: 23, L: 5, Precision:0.08504672897196262\n",
      "K: 23, L: 6, Precision:0.11588785046728972\n",
      "K: 23, L: 7, Precision:0.1205607476635514\n",
      "K: 23, L: 8, Precision:0.12710280373831775\n",
      "K: 23, L: 9, Precision:0.16074766355140188\n",
      "K: 23, L: 10, Precision:0.18691588785046728\n",
      "K: 24, L: 1, Precision:0.03177570093457944\n",
      "K: 24, L: 2, Precision:0.029906542056074768\n",
      "K: 24, L: 3, Precision:0.07009345794392523\n",
      "K: 24, L: 4, Precision:0.08130841121495327\n",
      "K: 24, L: 5, Precision:0.07009345794392523\n",
      "K: 24, L: 6, Precision:0.09813084112149532\n",
      "K: 24, L: 7, Precision:0.10373831775700934\n",
      "K: 24, L: 8, Precision:0.11775700934579439\n",
      "K: 24, L: 9, Precision:0.15514018691588785\n",
      "K: 24, L: 10, Precision:0.1383177570093458\n",
      "K: 25, L: 1, Precision:0.014018691588785047\n",
      "K: 25, L: 2, Precision:0.03644859813084112\n",
      "K: 25, L: 3, Precision:0.038317757009345796\n",
      "K: 25, L: 4, Precision:0.06542056074766354\n",
      "K: 25, L: 5, Precision:0.07850467289719626\n",
      "K: 25, L: 6, Precision:0.08785046728971962\n",
      "K: 25, L: 7, Precision:0.10934579439252337\n",
      "K: 25, L: 8, Precision:0.09065420560747664\n",
      "K: 25, L: 9, Precision:0.12149532710280374\n",
      "K: 25, L: 10, Precision:0.12242990654205607\n",
      "K: 26, L: 1, Precision:0.020560747663551402\n",
      "K: 26, L: 2, Precision:0.029906542056074768\n",
      "K: 26, L: 3, Precision:0.029906542056074768\n",
      "K: 26, L: 4, Precision:0.056074766355140186\n",
      "K: 26, L: 5, Precision:0.058878504672897194\n",
      "K: 26, L: 6, Precision:0.07009345794392523\n",
      "K: 26, L: 7, Precision:0.06635514018691589\n",
      "K: 26, L: 8, Precision:0.08971962616822429\n",
      "K: 26, L: 9, Precision:0.09719626168224299\n",
      "K: 26, L: 10, Precision:0.10467289719626169\n",
      "K: 27, L: 1, Precision:0.024299065420560748\n",
      "K: 27, L: 2, Precision:0.02897196261682243\n",
      "K: 27, L: 3, Precision:0.038317757009345796\n",
      "K: 27, L: 4, Precision:0.04672897196261682\n",
      "K: 27, L: 5, Precision:0.052336448598130844\n",
      "K: 27, L: 6, Precision:0.06542056074766354\n",
      "K: 27, L: 7, Precision:0.0794392523364486\n",
      "K: 27, L: 8, Precision:0.08130841121495327\n",
      "K: 27, L: 9, Precision:0.10467289719626169\n",
      "K: 27, L: 10, Precision:0.11121495327102804\n",
      "K: 28, L: 1, Precision:0.008411214953271028\n",
      "K: 28, L: 2, Precision:0.022429906542056073\n",
      "K: 28, L: 3, Precision:0.03177570093457944\n",
      "K: 28, L: 4, Precision:0.03644859813084112\n",
      "K: 28, L: 5, Precision:0.056074766355140186\n",
      "K: 28, L: 6, Precision:0.05794392523364486\n",
      "K: 28, L: 7, Precision:0.059813084112149535\n",
      "K: 28, L: 8, Precision:0.07196261682242991\n",
      "K: 28, L: 9, Precision:0.08971962616822429\n",
      "K: 28, L: 10, Precision:0.08971962616822429\n",
      "K: 29, L: 1, Precision:0.011214953271028037\n",
      "K: 29, L: 2, Precision:0.017757009345794394\n",
      "K: 29, L: 3, Precision:0.037383177570093455\n",
      "K: 29, L: 4, Precision:0.03644859813084112\n",
      "K: 29, L: 5, Precision:0.0514018691588785\n",
      "K: 29, L: 6, Precision:0.03925233644859813\n",
      "K: 29, L: 7, Precision:0.0514018691588785\n",
      "K: 29, L: 8, Precision:0.06635514018691589\n",
      "K: 29, L: 9, Precision:0.08411214953271028\n",
      "K: 29, L: 10, Precision:0.09813084112149532\n",
      "K: 30, L: 1, Precision:0.0065420560747663555\n",
      "K: 30, L: 2, Precision:0.017757009345794394\n",
      "K: 30, L: 3, Precision:0.018691588785046728\n",
      "K: 30, L: 4, Precision:0.038317757009345796\n",
      "K: 30, L: 5, Precision:0.04205607476635514\n",
      "K: 30, L: 6, Precision:0.05327102803738318\n",
      "K: 30, L: 7, Precision:0.05514018691588785\n",
      "K: 30, L: 8, Precision:0.05700934579439252\n",
      "K: 30, L: 9, Precision:0.06635514018691589\n",
      "K: 30, L: 10, Precision:0.059813084112149535\n",
      "Max precision: 1.0, k: 4, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(30):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
