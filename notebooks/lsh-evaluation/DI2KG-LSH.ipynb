{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'DI2KG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.02352312, -0.00855386, -0.13766373, -0.14595028, -0.01095964,\n",
      "        -0.19326383,  0.03448276, -0.23175621,  0.20128308, -0.01256349],\n",
      "       [-0.17351916, -0.04390244,  0.1029036 , -0.18885017, -0.03182346,\n",
      "         0.01277584,  0.16445993, -0.01068525,  0.11056911, -0.16051103],\n",
      "       [ 0.09033424, -0.1321891 ,  0.12767239,  0.12104788,  0.17464619,\n",
      "        -0.09003312, -0.00542005, -0.17856067, -0.06654622, -0.01355014],\n",
      "       [ 0.18655266, -0.13797124,  0.02545667,  0.08608628, -0.0551885 ,\n",
      "        -0.11562379, -0.05071901, -0.1467159 , -0.17567042, -0.02001555],\n",
      "       [-0.16437537, -0.00079697,  0.06056983, -0.18748755, -0.16935645,\n",
      "         0.07989639, -0.0938434 ,  0.04562662,  0.13369197, -0.06435545]]), array([[ 0.11229947,  0.18015858, -0.03651116,  0.10842707, -0.06214273,\n",
      "         0.12686705,  0.13682464,  0.01567398,  0.12520745, -0.09588788],\n",
      "       [-0.23640167,  0.08403068,  0.0292887 , -0.05648536,  0.02475593,\n",
      "         0.12726639, -0.05788006,  0.2011855 , -0.11331939, -0.06938633],\n",
      "       [ 0.07705644,  0.1354267 , -0.02003468,  0.1743402 , -0.02311693,\n",
      "        -0.04334425, -0.17877095, -0.1223271 ,  0.11577731,  0.10980543],\n",
      "       [ 0.02680921, -0.12861842, -0.04802632, -0.15773026,  0.12697368,\n",
      "         0.13799342,  0.14572368, -0.09013158,  0.07269737,  0.06529605],\n",
      "       [ 0.12479441, -0.10978618, -0.03556743,  0.18421053, -0.12911184,\n",
      "         0.14473684, -0.05715461, -0.13363487, -0.0078125 ,  0.07319079]])]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:1.0\n",
      "K: 1, L: 2, Precision:1.0\n",
      "K: 1, L: 3, Precision:1.0\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.6086956521739131\n",
      "K: 2, L: 2, Precision:0.782608695652174\n",
      "K: 2, L: 3, Precision:1.0\n",
      "K: 2, L: 4, Precision:1.0\n",
      "K: 2, L: 5, Precision:1.0\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.6086956521739131\n",
      "K: 3, L: 2, Precision:0.6521739130434783\n",
      "K: 3, L: 3, Precision:1.0\n",
      "K: 3, L: 4, Precision:0.8695652173913043\n",
      "K: 3, L: 5, Precision:1.0\n",
      "K: 3, L: 6, Precision:1.0\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.5217391304347826\n",
      "K: 4, L: 2, Precision:0.6956521739130435\n",
      "K: 4, L: 3, Precision:0.782608695652174\n",
      "K: 4, L: 4, Precision:0.9565217391304348\n",
      "K: 4, L: 5, Precision:1.0\n",
      "K: 4, L: 6, Precision:0.9130434782608695\n",
      "K: 4, L: 7, Precision:0.9565217391304348\n",
      "K: 4, L: 8, Precision:1.0\n",
      "K: 4, L: 9, Precision:1.0\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.2608695652173913\n",
      "K: 5, L: 2, Precision:0.5217391304347826\n",
      "K: 5, L: 3, Precision:0.4782608695652174\n",
      "K: 5, L: 4, Precision:0.8695652173913043\n",
      "K: 5, L: 5, Precision:0.8260869565217391\n",
      "K: 5, L: 6, Precision:0.9130434782608695\n",
      "K: 5, L: 7, Precision:1.0\n",
      "K: 5, L: 8, Precision:1.0\n",
      "K: 5, L: 9, Precision:1.0\n",
      "K: 5, L: 10, Precision:0.9565217391304348\n",
      "K: 6, L: 1, Precision:0.13043478260869565\n",
      "K: 6, L: 2, Precision:0.5652173913043478\n",
      "K: 6, L: 3, Precision:0.34782608695652173\n",
      "K: 6, L: 4, Precision:0.9130434782608695\n",
      "K: 6, L: 5, Precision:0.8260869565217391\n",
      "K: 6, L: 6, Precision:0.782608695652174\n",
      "K: 6, L: 7, Precision:1.0\n",
      "K: 6, L: 8, Precision:0.9130434782608695\n",
      "K: 6, L: 9, Precision:0.9565217391304348\n",
      "K: 6, L: 10, Precision:0.9130434782608695\n",
      "K: 7, L: 1, Precision:0.13043478260869565\n",
      "K: 7, L: 2, Precision:0.391304347826087\n",
      "K: 7, L: 3, Precision:0.6086956521739131\n",
      "K: 7, L: 4, Precision:0.6086956521739131\n",
      "K: 7, L: 5, Precision:0.6956521739130435\n",
      "K: 7, L: 6, Precision:0.8260869565217391\n",
      "K: 7, L: 7, Precision:0.6956521739130435\n",
      "K: 7, L: 8, Precision:0.8260869565217391\n",
      "K: 7, L: 9, Precision:0.9130434782608695\n",
      "K: 7, L: 10, Precision:0.8695652173913043\n",
      "K: 8, L: 1, Precision:0.4782608695652174\n",
      "K: 8, L: 2, Precision:0.30434782608695654\n",
      "K: 8, L: 3, Precision:0.30434782608695654\n",
      "K: 8, L: 4, Precision:0.4782608695652174\n",
      "K: 8, L: 5, Precision:0.5652173913043478\n",
      "K: 8, L: 6, Precision:0.5217391304347826\n",
      "K: 8, L: 7, Precision:0.5652173913043478\n",
      "K: 8, L: 8, Precision:0.7391304347826086\n",
      "K: 8, L: 9, Precision:0.6521739130434783\n",
      "K: 8, L: 10, Precision:0.6956521739130435\n",
      "K: 9, L: 1, Precision:0.17391304347826086\n",
      "K: 9, L: 2, Precision:0.17391304347826086\n",
      "K: 9, L: 3, Precision:0.391304347826087\n",
      "K: 9, L: 4, Precision:0.6086956521739131\n",
      "K: 9, L: 5, Precision:0.5652173913043478\n",
      "K: 9, L: 6, Precision:0.7391304347826086\n",
      "K: 9, L: 7, Precision:0.5217391304347826\n",
      "K: 9, L: 8, Precision:0.6086956521739131\n",
      "K: 9, L: 9, Precision:0.4782608695652174\n",
      "K: 9, L: 10, Precision:0.6086956521739131\n",
      "K: 10, L: 1, Precision:0.17391304347826086\n",
      "K: 10, L: 2, Precision:0.21739130434782608\n",
      "K: 10, L: 3, Precision:0.30434782608695654\n",
      "K: 10, L: 4, Precision:0.5217391304347826\n",
      "K: 10, L: 5, Precision:0.34782608695652173\n",
      "K: 10, L: 6, Precision:0.4782608695652174\n",
      "K: 10, L: 7, Precision:0.5217391304347826\n",
      "K: 10, L: 8, Precision:0.7391304347826086\n",
      "K: 10, L: 9, Precision:0.5652173913043478\n",
      "K: 10, L: 10, Precision:0.7391304347826086\n",
      "K: 11, L: 1, Precision:0.17391304347826086\n",
      "K: 11, L: 2, Precision:0.2608695652173913\n",
      "K: 11, L: 3, Precision:0.21739130434782608\n",
      "K: 11, L: 4, Precision:0.2608695652173913\n",
      "K: 11, L: 5, Precision:0.30434782608695654\n",
      "K: 11, L: 6, Precision:0.391304347826087\n",
      "K: 11, L: 7, Precision:0.4782608695652174\n",
      "K: 11, L: 8, Precision:0.43478260869565216\n",
      "K: 11, L: 9, Precision:0.43478260869565216\n",
      "K: 11, L: 10, Precision:0.43478260869565216\n",
      "K: 12, L: 1, Precision:0.08695652173913043\n",
      "K: 12, L: 2, Precision:0.30434782608695654\n",
      "K: 12, L: 3, Precision:0.2608695652173913\n",
      "K: 12, L: 4, Precision:0.43478260869565216\n",
      "K: 12, L: 5, Precision:0.2608695652173913\n",
      "K: 12, L: 6, Precision:0.391304347826087\n",
      "K: 12, L: 7, Precision:0.5217391304347826\n",
      "K: 12, L: 8, Precision:0.391304347826087\n",
      "K: 12, L: 9, Precision:0.43478260869565216\n",
      "K: 12, L: 10, Precision:0.4782608695652174\n",
      "K: 13, L: 1, Precision:0.08695652173913043\n",
      "K: 13, L: 2, Precision:0.30434782608695654\n",
      "K: 13, L: 3, Precision:0.21739130434782608\n",
      "K: 13, L: 4, Precision:0.30434782608695654\n",
      "K: 13, L: 5, Precision:0.2608695652173913\n",
      "K: 13, L: 6, Precision:0.43478260869565216\n",
      "K: 13, L: 7, Precision:0.30434782608695654\n",
      "K: 13, L: 8, Precision:0.4782608695652174\n",
      "K: 13, L: 9, Precision:0.34782608695652173\n",
      "K: 13, L: 10, Precision:0.5217391304347826\n",
      "K: 14, L: 1, Precision:0.043478260869565216\n",
      "K: 14, L: 2, Precision:0.2608695652173913\n",
      "K: 14, L: 3, Precision:0.13043478260869565\n",
      "K: 14, L: 4, Precision:0.13043478260869565\n",
      "K: 14, L: 5, Precision:0.17391304347826086\n",
      "K: 14, L: 6, Precision:0.34782608695652173\n",
      "K: 14, L: 7, Precision:0.2608695652173913\n",
      "K: 14, L: 8, Precision:0.391304347826087\n",
      "K: 14, L: 9, Precision:0.43478260869565216\n",
      "K: 14, L: 10, Precision:0.30434782608695654\n",
      "K: 15, L: 1, Precision:0.30434782608695654\n",
      "K: 15, L: 2, Precision:0.043478260869565216\n",
      "K: 15, L: 3, Precision:0.08695652173913043\n",
      "K: 15, L: 4, Precision:0.17391304347826086\n",
      "K: 15, L: 5, Precision:0.2608695652173913\n",
      "K: 15, L: 6, Precision:0.30434782608695654\n",
      "K: 15, L: 7, Precision:0.34782608695652173\n",
      "K: 15, L: 8, Precision:0.2608695652173913\n",
      "K: 15, L: 9, Precision:0.21739130434782608\n",
      "K: 15, L: 10, Precision:0.34782608695652173\n",
      "K: 16, L: 1, Precision:0.0\n",
      "K: 16, L: 2, Precision:0.043478260869565216\n",
      "K: 16, L: 3, Precision:0.21739130434782608\n",
      "K: 16, L: 4, Precision:0.4782608695652174\n",
      "K: 16, L: 5, Precision:0.30434782608695654\n",
      "K: 16, L: 6, Precision:0.2608695652173913\n",
      "K: 16, L: 7, Precision:0.13043478260869565\n",
      "K: 16, L: 8, Precision:0.43478260869565216\n",
      "K: 16, L: 9, Precision:0.30434782608695654\n",
      "K: 16, L: 10, Precision:0.2608695652173913\n",
      "K: 17, L: 1, Precision:0.043478260869565216\n",
      "K: 17, L: 2, Precision:0.08695652173913043\n",
      "K: 17, L: 3, Precision:0.08695652173913043\n",
      "K: 17, L: 4, Precision:0.08695652173913043\n",
      "K: 17, L: 5, Precision:0.13043478260869565\n",
      "K: 17, L: 6, Precision:0.13043478260869565\n",
      "K: 17, L: 7, Precision:0.2608695652173913\n",
      "K: 17, L: 8, Precision:0.43478260869565216\n",
      "K: 17, L: 9, Precision:0.391304347826087\n",
      "K: 17, L: 10, Precision:0.21739130434782608\n",
      "K: 18, L: 1, Precision:0.08695652173913043\n",
      "K: 18, L: 2, Precision:0.08695652173913043\n",
      "K: 18, L: 3, Precision:0.21739130434782608\n",
      "K: 18, L: 4, Precision:0.2608695652173913\n",
      "K: 18, L: 5, Precision:0.17391304347826086\n",
      "K: 18, L: 6, Precision:0.2608695652173913\n",
      "K: 18, L: 7, Precision:0.30434782608695654\n",
      "K: 18, L: 8, Precision:0.21739130434782608\n",
      "K: 18, L: 9, Precision:0.391304347826087\n",
      "K: 18, L: 10, Precision:0.30434782608695654\n",
      "K: 19, L: 1, Precision:0.043478260869565216\n",
      "K: 19, L: 2, Precision:0.21739130434782608\n",
      "K: 19, L: 3, Precision:0.13043478260869565\n",
      "K: 19, L: 4, Precision:0.17391304347826086\n",
      "K: 19, L: 5, Precision:0.2608695652173913\n",
      "K: 19, L: 6, Precision:0.2608695652173913\n",
      "K: 19, L: 7, Precision:0.21739130434782608\n",
      "K: 19, L: 8, Precision:0.2608695652173913\n",
      "K: 19, L: 9, Precision:0.30434782608695654\n",
      "K: 19, L: 10, Precision:0.30434782608695654\n",
      "K: 20, L: 1, Precision:0.13043478260869565\n",
      "K: 20, L: 2, Precision:0.043478260869565216\n",
      "K: 20, L: 3, Precision:0.13043478260869565\n",
      "K: 20, L: 4, Precision:0.21739130434782608\n",
      "K: 20, L: 5, Precision:0.21739130434782608\n",
      "K: 20, L: 6, Precision:0.30434782608695654\n",
      "K: 20, L: 7, Precision:0.13043478260869565\n",
      "K: 20, L: 8, Precision:0.17391304347826086\n",
      "K: 20, L: 9, Precision:0.17391304347826086\n",
      "K: 20, L: 10, Precision:0.21739130434782608\n",
      "K: 21, L: 1, Precision:0.043478260869565216\n",
      "K: 21, L: 2, Precision:0.13043478260869565\n",
      "K: 21, L: 3, Precision:0.13043478260869565\n",
      "K: 21, L: 4, Precision:0.13043478260869565\n",
      "K: 21, L: 5, Precision:0.17391304347826086\n",
      "K: 21, L: 6, Precision:0.21739130434782608\n",
      "K: 21, L: 7, Precision:0.13043478260869565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 21, L: 8, Precision:0.13043478260869565\n",
      "K: 21, L: 9, Precision:0.21739130434782608\n",
      "K: 21, L: 10, Precision:0.2608695652173913\n",
      "K: 22, L: 1, Precision:0.0\n",
      "K: 22, L: 2, Precision:0.17391304347826086\n",
      "K: 22, L: 3, Precision:0.13043478260869565\n",
      "K: 22, L: 4, Precision:0.13043478260869565\n",
      "K: 22, L: 5, Precision:0.21739130434782608\n",
      "K: 22, L: 6, Precision:0.08695652173913043\n",
      "K: 22, L: 7, Precision:0.17391304347826086\n",
      "K: 22, L: 8, Precision:0.13043478260869565\n",
      "K: 22, L: 9, Precision:0.2608695652173913\n",
      "K: 22, L: 10, Precision:0.21739130434782608\n",
      "K: 23, L: 1, Precision:0.043478260869565216\n",
      "K: 23, L: 2, Precision:0.21739130434782608\n",
      "K: 23, L: 3, Precision:0.043478260869565216\n",
      "K: 23, L: 4, Precision:0.08695652173913043\n",
      "K: 23, L: 5, Precision:0.21739130434782608\n",
      "K: 23, L: 6, Precision:0.043478260869565216\n",
      "K: 23, L: 7, Precision:0.13043478260869565\n",
      "K: 23, L: 8, Precision:0.21739130434782608\n",
      "K: 23, L: 9, Precision:0.17391304347826086\n",
      "K: 23, L: 10, Precision:0.13043478260869565\n",
      "K: 24, L: 1, Precision:0.043478260869565216\n",
      "K: 24, L: 2, Precision:0.043478260869565216\n",
      "K: 24, L: 3, Precision:0.043478260869565216\n",
      "K: 24, L: 4, Precision:0.08695652173913043\n",
      "K: 24, L: 5, Precision:0.13043478260869565\n",
      "K: 24, L: 6, Precision:0.17391304347826086\n",
      "K: 24, L: 7, Precision:0.13043478260869565\n",
      "K: 24, L: 8, Precision:0.17391304347826086\n",
      "K: 24, L: 9, Precision:0.21739130434782608\n",
      "K: 24, L: 10, Precision:0.13043478260869565\n",
      "K: 25, L: 1, Precision:0.0\n",
      "K: 25, L: 2, Precision:0.0\n",
      "K: 25, L: 3, Precision:0.17391304347826086\n",
      "K: 25, L: 4, Precision:0.17391304347826086\n",
      "K: 25, L: 5, Precision:0.043478260869565216\n",
      "K: 25, L: 6, Precision:0.17391304347826086\n",
      "K: 25, L: 7, Precision:0.13043478260869565\n",
      "K: 25, L: 8, Precision:0.17391304347826086\n",
      "K: 25, L: 9, Precision:0.043478260869565216\n",
      "K: 25, L: 10, Precision:0.13043478260869565\n",
      "K: 26, L: 1, Precision:0.08695652173913043\n",
      "K: 26, L: 2, Precision:0.043478260869565216\n",
      "K: 26, L: 3, Precision:0.043478260869565216\n",
      "K: 26, L: 4, Precision:0.08695652173913043\n",
      "K: 26, L: 5, Precision:0.043478260869565216\n",
      "K: 26, L: 6, Precision:0.13043478260869565\n",
      "K: 26, L: 7, Precision:0.13043478260869565\n",
      "K: 26, L: 8, Precision:0.13043478260869565\n",
      "K: 26, L: 9, Precision:0.13043478260869565\n",
      "K: 26, L: 10, Precision:0.08695652173913043\n",
      "K: 27, L: 1, Precision:0.043478260869565216\n",
      "K: 27, L: 2, Precision:0.0\n",
      "K: 27, L: 3, Precision:0.13043478260869565\n",
      "K: 27, L: 4, Precision:0.0\n",
      "K: 27, L: 5, Precision:0.043478260869565216\n",
      "K: 27, L: 6, Precision:0.08695652173913043\n",
      "K: 27, L: 7, Precision:0.08695652173913043\n",
      "K: 27, L: 8, Precision:0.21739130434782608\n",
      "K: 27, L: 9, Precision:0.17391304347826086\n",
      "K: 27, L: 10, Precision:0.13043478260869565\n",
      "K: 28, L: 1, Precision:0.08695652173913043\n",
      "K: 28, L: 2, Precision:0.08695652173913043\n",
      "K: 28, L: 3, Precision:0.043478260869565216\n",
      "K: 28, L: 4, Precision:0.0\n",
      "K: 28, L: 5, Precision:0.043478260869565216\n",
      "K: 28, L: 6, Precision:0.17391304347826086\n",
      "K: 28, L: 7, Precision:0.043478260869565216\n",
      "K: 28, L: 8, Precision:0.17391304347826086\n",
      "K: 28, L: 9, Precision:0.08695652173913043\n",
      "K: 28, L: 10, Precision:0.17391304347826086\n",
      "K: 29, L: 1, Precision:0.08695652173913043\n",
      "K: 29, L: 2, Precision:0.043478260869565216\n",
      "K: 29, L: 3, Precision:0.043478260869565216\n",
      "K: 29, L: 4, Precision:0.08695652173913043\n",
      "K: 29, L: 5, Precision:0.13043478260869565\n",
      "K: 29, L: 6, Precision:0.08695652173913043\n",
      "K: 29, L: 7, Precision:0.043478260869565216\n",
      "K: 29, L: 8, Precision:0.08695652173913043\n",
      "K: 29, L: 9, Precision:0.08695652173913043\n",
      "K: 29, L: 10, Precision:0.13043478260869565\n",
      "K: 30, L: 1, Precision:0.08695652173913043\n",
      "K: 30, L: 2, Precision:0.08695652173913043\n",
      "K: 30, L: 3, Precision:0.043478260869565216\n",
      "K: 30, L: 4, Precision:0.08695652173913043\n",
      "K: 30, L: 5, Precision:0.08695652173913043\n",
      "K: 30, L: 6, Precision:0.043478260869565216\n",
      "K: 30, L: 7, Precision:0.043478260869565216\n",
      "K: 30, L: 8, Precision:0.08695652173913043\n",
      "K: 30, L: 9, Precision:0.08695652173913043\n",
      "K: 30, L: 10, Precision:0.08695652173913043\n",
      "Max precision: 1.0, k: 6, L: 7\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(30):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
