{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T0l0CtAUHWQ"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'DBLP-ACM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaVNMZkjUJR0"
   },
   "outputs": [],
   "source": [
    "class LSH :\n",
    "  \n",
    "    # Random limits, const\n",
    "    __max_rand =  1000\n",
    "    __min_rand = -1000\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, k, L, embedding_size = 150):\n",
    "        \n",
    "        # Number of hash function\n",
    "        self.k = k\n",
    "        \n",
    "        # Number of attempts\n",
    "        self.L = L\n",
    "        \n",
    "        # Embedding length \n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Random matrices\n",
    "        self.normalized_random_matrices = []\n",
    "        \n",
    "        for i in range(self.L):\n",
    "            random_matrix = np.random.randint(self.__min_rand, self.__max_rand,(self.k, self.embedding_size));\n",
    "            \n",
    "            # Append normalized random matrices\n",
    "            self.normalized_random_matrices.append(normalize(random_matrix, axis=1, norm='l1'))\n",
    "        \n",
    "    \n",
    "    # Locality Sensitive hash function\n",
    "    def locality_sensitive_hash(self, embedding, matrix_index):\n",
    "        out = 0\n",
    "      \n",
    "        for h in self.normalized_random_matrices[matrix_index]:\n",
    "            if (np.dot(h, embedding) >= 0):\n",
    "                out = (out << 1) | 1\n",
    "            else:\n",
    "                out = (out << 1) | 0\n",
    "\n",
    "        return out\n",
    "      \n",
    "    # Divide in buckets using L-th matrix\n",
    "    def divide_in_buckets(self, embeddings, matrix_index):\n",
    "        out = {}\n",
    "        for embedding in embeddings:\n",
    "            hash = self.locality_sensitive_hash(embedding, matrix_index)\n",
    "            if (hash in out):\n",
    "                out[hash].append(embedding)\n",
    "            else:\n",
    "                out[hash] = [embedding]\n",
    "            \n",
    "        return out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA_rrzuWVTeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.14205246,  0.01161767, -0.11582468,  0.07516282,  0.16000704,\n",
      "        -0.06037669, -0.15595846,  0.08378807, -0.06724168, -0.12797043],\n",
      "       [ 0.0684727 , -0.11774744,  0.21267065, -0.05738055,  0.08148464,\n",
      "         0.02367747,  0.13011945, -0.159343  ,  0.09001706, -0.05908703],\n",
      "       [-0.1000899 ,  0.06323045, -0.12406353, -0.12076716,  0.07132155,\n",
      "        -0.14204375,  0.1350015 , -0.08960144, -0.13035661,  0.02352412],\n",
      "       [ 0.02912621, -0.12962017, -0.09708738, -0.11463124,  0.0183955 ,\n",
      "         0.15329586, -0.14001022, -0.14018055,  0.00902742, -0.16862545],\n",
      "       [-0.05601454, -0.05469266,  0.10690681, -0.14177132, -0.15052875,\n",
      "        -0.03040317,  0.13912756, -0.09666226, -0.09418374,  0.12970919]]), array([[-0.17462334,  0.07242694, -0.16227991,  0.03793792,  0.09747686,\n",
      "        -0.16010165, -0.02940643, -0.11925939,  0.00471955, -0.14176802],\n",
      "       [ 0.14876458,  0.11187371, -0.01029513, -0.13332189,  0.16523679,\n",
      "         0.16489362, -0.00549073,  0.08562114, -0.11032944, -0.06417296],\n",
      "       [-0.08046927, -0.16259088,  0.14557171,  0.13631857,  0.01173166,\n",
      "        -0.03883014,  0.10922009, -0.14689359, -0.11136814,  0.05700595],\n",
      "       [-0.16603215,  0.03532149,  0.13049915, -0.0784687 ,  0.20156514,\n",
      "        -0.09856176,  0.00994078, -0.0465313 , -0.20431472, -0.02876481],\n",
      "       [ 0.13527809, -0.06026607, -0.04888604,  0.11315916, -0.12998878,\n",
      "         0.08671261, -0.15034461, -0.07757653,  0.10225998,  0.09552813]])]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "test = LSH(k=5, L=2, embedding_size=10)\n",
    "print(test.normalized_random_matrices)\n",
    "\n",
    "print(test.locality_sensitive_hash([1,2,3,4,5,6,7,8,9,10], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYp-rvQFWE9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "## almost equals\n",
    "embeddings = [[1.2345,2,3,4,5,6,10.4,8,9,10],[1,2,3,4,5,6,7,8,9,10],[1,2,3,5,5,6,7,8,9,10]]\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n",
    "\n",
    "## not equals\n",
    "embeddings = np.random.randint(-10000, 10000,(10000, 10))\n",
    "print(len(test.divide_in_buckets(embeddings, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG5IMt9GbtC4"
   },
   "outputs": [],
   "source": [
    "## TEST BLOCKING PERFORMANCE\n",
    "#    Basta che per ogni tupla vado a prendere la sua corrispondente, ne calcolo\n",
    "#     i vari L hash e controllo che almeno uno sia uguale e incremento un\n",
    "#     contatore. La precisione Ã¨ contatore/numero di tuple controllate, giusto?\n",
    "def performance_test(filtered_dataset, k, L, embedding_size):\n",
    "    \n",
    "    match_found = 0\n",
    "    \n",
    "    lsh = LSH(k, L, embedding_size)\n",
    "    \n",
    "    # for each elemt in dataset\n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        x_embedding = np.array(literal_eval(row['left_table']))\n",
    "        y_embedding = np.array(literal_eval(row['right_table']))\n",
    "          \n",
    "        x_hashs = set()\n",
    "        y_hashs = set()\n",
    "        for i in range(L):\n",
    "            x_hashs.add(lsh.locality_sensitive_hash(x_embedding, i))\n",
    "            y_hashs.add(lsh.locality_sensitive_hash(y_embedding, i))\n",
    "        \n",
    "        if (len(set.intersection(x_hashs, y_hashs)) > 0):\n",
    "            match_found += 1\n",
    "  \n",
    "    \n",
    "    return match_found / len(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ul6R9eM_Gr-v",
    "outputId": "eabac908-852d-49d0-b9ed-bf5b4770a684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, L: 1, Precision:0.9684684684684685\n",
      "K: 1, L: 2, Precision:1.0\n",
      "K: 1, L: 3, Precision:1.0\n",
      "K: 1, L: 4, Precision:1.0\n",
      "K: 1, L: 5, Precision:1.0\n",
      "K: 1, L: 6, Precision:1.0\n",
      "K: 1, L: 7, Precision:1.0\n",
      "K: 1, L: 8, Precision:1.0\n",
      "K: 1, L: 9, Precision:1.0\n",
      "K: 1, L: 10, Precision:1.0\n",
      "K: 2, L: 1, Precision:0.9166666666666666\n",
      "K: 2, L: 2, Precision:0.9977477477477478\n",
      "K: 2, L: 3, Precision:1.0\n",
      "K: 2, L: 4, Precision:1.0\n",
      "K: 2, L: 5, Precision:1.0\n",
      "K: 2, L: 6, Precision:1.0\n",
      "K: 2, L: 7, Precision:1.0\n",
      "K: 2, L: 8, Precision:1.0\n",
      "K: 2, L: 9, Precision:1.0\n",
      "K: 2, L: 10, Precision:1.0\n",
      "K: 3, L: 1, Precision:0.8986486486486487\n",
      "K: 3, L: 2, Precision:0.990990990990991\n",
      "K: 3, L: 3, Precision:0.9954954954954955\n",
      "K: 3, L: 4, Precision:1.0\n",
      "K: 3, L: 5, Precision:1.0\n",
      "K: 3, L: 6, Precision:1.0\n",
      "K: 3, L: 7, Precision:1.0\n",
      "K: 3, L: 8, Precision:1.0\n",
      "K: 3, L: 9, Precision:1.0\n",
      "K: 3, L: 10, Precision:1.0\n",
      "K: 4, L: 1, Precision:0.8896396396396397\n",
      "K: 4, L: 2, Precision:0.9594594594594594\n",
      "K: 4, L: 3, Precision:0.990990990990991\n",
      "K: 4, L: 4, Precision:0.9977477477477478\n",
      "K: 4, L: 5, Precision:1.0\n",
      "K: 4, L: 6, Precision:1.0\n",
      "K: 4, L: 7, Precision:1.0\n",
      "K: 4, L: 8, Precision:1.0\n",
      "K: 4, L: 9, Precision:1.0\n",
      "K: 4, L: 10, Precision:1.0\n",
      "K: 5, L: 1, Precision:0.7815315315315315\n",
      "K: 5, L: 2, Precision:0.9662162162162162\n",
      "K: 5, L: 3, Precision:0.990990990990991\n",
      "K: 5, L: 4, Precision:0.9977477477477478\n",
      "K: 5, L: 5, Precision:1.0\n",
      "K: 5, L: 6, Precision:0.9954954954954955\n",
      "K: 5, L: 7, Precision:0.9954954954954955\n",
      "K: 5, L: 8, Precision:1.0\n",
      "K: 5, L: 9, Precision:1.0\n",
      "K: 5, L: 10, Precision:1.0\n",
      "K: 6, L: 1, Precision:0.7702702702702703\n",
      "K: 6, L: 2, Precision:0.9279279279279279\n",
      "K: 6, L: 3, Precision:0.9819819819819819\n",
      "K: 6, L: 4, Precision:0.9887387387387387\n",
      "K: 6, L: 5, Precision:0.9954954954954955\n",
      "K: 6, L: 6, Precision:0.9954954954954955\n",
      "K: 6, L: 7, Precision:0.9977477477477478\n",
      "K: 6, L: 8, Precision:0.9954954954954955\n",
      "K: 6, L: 9, Precision:1.0\n",
      "K: 6, L: 10, Precision:1.0\n",
      "K: 7, L: 1, Precision:0.8333333333333334\n",
      "K: 7, L: 2, Precision:0.9481981981981982\n",
      "K: 7, L: 3, Precision:0.963963963963964\n",
      "K: 7, L: 4, Precision:0.9707207207207207\n",
      "K: 7, L: 5, Precision:0.9864864864864865\n",
      "K: 7, L: 6, Precision:0.9954954954954955\n",
      "K: 7, L: 7, Precision:0.9954954954954955\n",
      "K: 7, L: 8, Precision:0.9977477477477478\n",
      "K: 7, L: 9, Precision:0.9977477477477478\n",
      "K: 7, L: 10, Precision:1.0\n",
      "K: 8, L: 1, Precision:0.786036036036036\n",
      "K: 8, L: 2, Precision:0.8806306306306306\n",
      "K: 8, L: 3, Precision:0.9684684684684685\n",
      "K: 8, L: 4, Precision:0.963963963963964\n",
      "K: 8, L: 5, Precision:0.9797297297297297\n",
      "K: 8, L: 6, Precision:0.9977477477477478\n",
      "K: 8, L: 7, Precision:0.9954954954954955\n",
      "K: 8, L: 8, Precision:0.9977477477477478\n",
      "K: 8, L: 9, Precision:0.9977477477477478\n",
      "K: 8, L: 10, Precision:0.9954954954954955\n",
      "K: 9, L: 1, Precision:0.7297297297297297\n",
      "K: 9, L: 2, Precision:0.8986486486486487\n",
      "K: 9, L: 3, Precision:0.954954954954955\n",
      "K: 9, L: 4, Precision:0.9572072072072072\n",
      "K: 9, L: 5, Precision:0.9707207207207207\n",
      "K: 9, L: 6, Precision:0.9864864864864865\n",
      "K: 9, L: 7, Precision:0.990990990990991\n",
      "K: 9, L: 8, Precision:0.990990990990991\n",
      "K: 9, L: 9, Precision:0.9977477477477478\n",
      "K: 9, L: 10, Precision:0.9954954954954955\n",
      "K: 10, L: 1, Precision:0.6891891891891891\n",
      "K: 10, L: 2, Precision:0.8963963963963963\n",
      "K: 10, L: 3, Precision:0.9459459459459459\n",
      "K: 10, L: 4, Precision:0.9662162162162162\n",
      "K: 10, L: 5, Precision:0.9752252252252253\n",
      "K: 10, L: 6, Precision:0.9842342342342343\n",
      "K: 10, L: 7, Precision:0.9887387387387387\n",
      "K: 10, L: 8, Precision:0.990990990990991\n",
      "K: 10, L: 9, Precision:0.9932432432432432\n",
      "K: 10, L: 10, Precision:0.990990990990991\n",
      "K: 11, L: 1, Precision:0.6216216216216216\n",
      "K: 11, L: 2, Precision:0.8873873873873874\n",
      "K: 11, L: 3, Precision:0.9211711711711712\n",
      "K: 11, L: 4, Precision:0.9594594594594594\n",
      "K: 11, L: 5, Precision:0.972972972972973\n",
      "K: 11, L: 6, Precision:0.9752252252252253\n",
      "K: 11, L: 7, Precision:0.9752252252252253\n",
      "K: 11, L: 8, Precision:0.9864864864864865\n",
      "K: 11, L: 9, Precision:0.9864864864864865\n",
      "K: 11, L: 10, Precision:0.9932432432432432\n",
      "K: 12, L: 1, Precision:0.6441441441441441\n",
      "K: 12, L: 2, Precision:0.8288288288288288\n",
      "K: 12, L: 3, Precision:0.9054054054054054\n",
      "K: 12, L: 4, Precision:0.9459459459459459\n",
      "K: 12, L: 5, Precision:0.9504504504504504\n",
      "K: 12, L: 6, Precision:0.9684684684684685\n",
      "K: 12, L: 7, Precision:0.972972972972973\n",
      "K: 12, L: 8, Precision:0.9842342342342343\n",
      "K: 12, L: 9, Precision:0.9864864864864865\n",
      "K: 12, L: 10, Precision:0.9932432432432432\n",
      "K: 13, L: 1, Precision:0.6351351351351351\n",
      "K: 13, L: 2, Precision:0.8130630630630631\n",
      "K: 13, L: 3, Precision:0.8873873873873874\n",
      "K: 13, L: 4, Precision:0.9211711711711712\n",
      "K: 13, L: 5, Precision:0.9594594594594594\n",
      "K: 13, L: 6, Precision:0.9684684684684685\n",
      "K: 13, L: 7, Precision:0.9752252252252253\n",
      "K: 13, L: 8, Precision:0.9819819819819819\n",
      "K: 13, L: 9, Precision:0.9842342342342343\n",
      "K: 13, L: 10, Precision:0.9842342342342343\n",
      "K: 14, L: 1, Precision:0.5765765765765766\n",
      "K: 14, L: 2, Precision:0.7567567567567568\n",
      "K: 14, L: 3, Precision:0.8896396396396397\n",
      "K: 14, L: 4, Precision:0.9211711711711712\n",
      "K: 14, L: 5, Precision:0.9504504504504504\n",
      "K: 14, L: 6, Precision:0.9594594594594594\n",
      "K: 14, L: 7, Precision:0.9662162162162162\n",
      "K: 14, L: 8, Precision:0.9797297297297297\n",
      "K: 14, L: 9, Precision:0.9752252252252253\n",
      "K: 14, L: 10, Precision:0.9797297297297297\n",
      "K: 15, L: 1, Precision:0.6351351351351351\n",
      "K: 15, L: 2, Precision:0.8018018018018018\n",
      "K: 15, L: 3, Precision:0.8761261261261262\n",
      "K: 15, L: 4, Precision:0.9301801801801802\n",
      "K: 15, L: 5, Precision:0.954954954954955\n",
      "K: 15, L: 6, Precision:0.9594594594594594\n",
      "K: 15, L: 7, Precision:0.9617117117117117\n",
      "K: 15, L: 8, Precision:0.972972972972973\n",
      "K: 15, L: 9, Precision:0.9752252252252253\n",
      "K: 15, L: 10, Precision:0.9752252252252253\n",
      "K: 16, L: 1, Precision:0.5945945945945946\n",
      "K: 16, L: 2, Precision:0.722972972972973\n",
      "K: 16, L: 3, Precision:0.8941441441441441\n",
      "K: 16, L: 4, Precision:0.9031531531531531\n",
      "K: 16, L: 5, Precision:0.9279279279279279\n",
      "K: 16, L: 6, Precision:0.9527027027027027\n",
      "K: 16, L: 7, Precision:0.954954954954955\n",
      "K: 16, L: 8, Precision:0.963963963963964\n",
      "K: 16, L: 9, Precision:0.972972972972973\n",
      "K: 16, L: 10, Precision:0.9617117117117117\n",
      "K: 17, L: 1, Precision:0.5563063063063063\n",
      "K: 17, L: 2, Precision:0.7297297297297297\n",
      "K: 17, L: 3, Precision:0.8423423423423423\n",
      "K: 17, L: 4, Precision:0.9054054054054054\n",
      "K: 17, L: 5, Precision:0.9031531531531531\n",
      "K: 17, L: 6, Precision:0.9279279279279279\n",
      "K: 17, L: 7, Precision:0.9391891891891891\n",
      "K: 17, L: 8, Precision:0.9617117117117117\n",
      "K: 17, L: 9, Precision:0.9594594594594594\n",
      "K: 17, L: 10, Precision:0.9594594594594594\n",
      "K: 18, L: 1, Precision:0.5608108108108109\n",
      "K: 18, L: 2, Precision:0.7432432432432432\n",
      "K: 18, L: 3, Precision:0.8265765765765766\n",
      "K: 18, L: 4, Precision:0.8738738738738738\n",
      "K: 18, L: 5, Precision:0.9144144144144144\n",
      "K: 18, L: 6, Precision:0.918918918918919\n",
      "K: 18, L: 7, Precision:0.9527027027027027\n",
      "K: 18, L: 8, Precision:0.9391891891891891\n",
      "K: 18, L: 9, Precision:0.954954954954955\n",
      "K: 18, L: 10, Precision:0.963963963963964\n",
      "K: 19, L: 1, Precision:0.536036036036036\n",
      "K: 19, L: 2, Precision:0.7319819819819819\n",
      "K: 19, L: 3, Precision:0.8018018018018018\n",
      "K: 19, L: 4, Precision:0.8806306306306306\n",
      "K: 19, L: 5, Precision:0.9144144144144144\n",
      "K: 19, L: 6, Precision:0.9121621621621622\n",
      "K: 19, L: 7, Precision:0.9301801801801802\n",
      "K: 19, L: 8, Precision:0.9481981981981982\n",
      "K: 19, L: 9, Precision:0.9391891891891891\n",
      "K: 19, L: 10, Precision:0.954954954954955\n",
      "K: 20, L: 1, Precision:0.5630630630630631\n",
      "K: 20, L: 2, Precision:0.7297297297297297\n",
      "K: 20, L: 3, Precision:0.8108108108108109\n",
      "K: 20, L: 4, Precision:0.8355855855855856\n",
      "K: 20, L: 5, Precision:0.8716216216216216\n",
      "K: 20, L: 6, Precision:0.9234234234234234\n",
      "K: 20, L: 7, Precision:0.9346846846846847\n",
      "K: 20, L: 8, Precision:0.9324324324324325\n",
      "K: 20, L: 9, Precision:0.9617117117117117\n",
      "K: 20, L: 10, Precision:0.9617117117117117\n",
      "K: 21, L: 1, Precision:0.49774774774774777\n",
      "K: 21, L: 2, Precision:0.6981981981981982\n",
      "K: 21, L: 3, Precision:0.786036036036036\n",
      "K: 21, L: 4, Precision:0.8513513513513513\n",
      "K: 21, L: 5, Precision:0.9031531531531531\n",
      "K: 21, L: 6, Precision:0.8986486486486487\n",
      "K: 21, L: 7, Precision:0.9256756756756757\n",
      "K: 21, L: 8, Precision:0.9279279279279279\n",
      "K: 21, L: 9, Precision:0.9391891891891891\n",
      "K: 21, L: 10, Precision:0.963963963963964\n",
      "K: 22, L: 1, Precision:0.45045045045045046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 22, L: 2, Precision:0.6486486486486487\n",
      "K: 22, L: 3, Precision:0.786036036036036\n",
      "K: 22, L: 4, Precision:0.8400900900900901\n",
      "K: 22, L: 5, Precision:0.8603603603603603\n",
      "K: 22, L: 6, Precision:0.8828828828828829\n",
      "K: 22, L: 7, Precision:0.9234234234234234\n",
      "K: 22, L: 8, Precision:0.9414414414414415\n",
      "K: 22, L: 9, Precision:0.9527027027027027\n",
      "K: 22, L: 10, Precision:0.9436936936936937\n",
      "K: 23, L: 1, Precision:0.44819819819819817\n",
      "K: 23, L: 2, Precision:0.6351351351351351\n",
      "K: 23, L: 3, Precision:0.7972972972972973\n",
      "K: 23, L: 4, Precision:0.8265765765765766\n",
      "K: 23, L: 5, Precision:0.8693693693693694\n",
      "K: 23, L: 6, Precision:0.8873873873873874\n",
      "K: 23, L: 7, Precision:0.9031531531531531\n",
      "K: 23, L: 8, Precision:0.9346846846846847\n",
      "K: 23, L: 9, Precision:0.9459459459459459\n",
      "K: 23, L: 10, Precision:0.9369369369369369\n",
      "K: 24, L: 1, Precision:0.4752252252252252\n",
      "K: 24, L: 2, Precision:0.6306306306306306\n",
      "K: 24, L: 3, Precision:0.740990990990991\n",
      "K: 24, L: 4, Precision:0.8175675675675675\n",
      "K: 24, L: 5, Precision:0.8536036036036037\n",
      "K: 24, L: 6, Precision:0.8851351351351351\n",
      "K: 24, L: 7, Precision:0.8581081081081081\n",
      "K: 24, L: 8, Precision:0.8963963963963963\n",
      "K: 24, L: 9, Precision:0.9324324324324325\n",
      "K: 24, L: 10, Precision:0.9324324324324325\n",
      "K: 25, L: 1, Precision:0.39864864864864863\n",
      "K: 25, L: 2, Precision:0.6058558558558559\n",
      "K: 25, L: 3, Precision:0.740990990990991\n",
      "K: 25, L: 4, Precision:0.8423423423423423\n",
      "K: 25, L: 5, Precision:0.8423423423423423\n",
      "K: 25, L: 6, Precision:0.8536036036036037\n",
      "K: 25, L: 7, Precision:0.8806306306306306\n",
      "K: 25, L: 8, Precision:0.9099099099099099\n",
      "K: 25, L: 9, Precision:0.8941441441441441\n",
      "K: 25, L: 10, Precision:0.9144144144144144\n",
      "K: 26, L: 1, Precision:0.42792792792792794\n",
      "K: 26, L: 2, Precision:0.6756756756756757\n",
      "K: 26, L: 3, Precision:0.7072072072072072\n",
      "K: 26, L: 4, Precision:0.7680180180180181\n",
      "K: 26, L: 5, Precision:0.8355855855855856\n",
      "K: 26, L: 6, Precision:0.8445945945945946\n",
      "K: 26, L: 7, Precision:0.8581081081081081\n",
      "K: 26, L: 8, Precision:0.8896396396396397\n",
      "K: 26, L: 9, Precision:0.9009009009009009\n",
      "K: 26, L: 10, Precision:0.9054054054054054\n",
      "K: 27, L: 1, Precision:0.39414414414414417\n",
      "K: 27, L: 2, Precision:0.5923423423423423\n",
      "K: 27, L: 3, Precision:0.7319819819819819\n",
      "K: 27, L: 4, Precision:0.7364864864864865\n",
      "K: 27, L: 5, Precision:0.8018018018018018\n",
      "K: 27, L: 6, Precision:0.8333333333333334\n",
      "K: 27, L: 7, Precision:0.8693693693693694\n",
      "K: 27, L: 8, Precision:0.8851351351351351\n",
      "K: 27, L: 9, Precision:0.8896396396396397\n",
      "K: 27, L: 10, Precision:0.9256756756756757\n",
      "K: 28, L: 1, Precision:0.39414414414414417\n",
      "K: 28, L: 2, Precision:0.5923423423423423\n",
      "K: 28, L: 3, Precision:0.7184684684684685\n",
      "K: 28, L: 4, Precision:0.7747747747747747\n",
      "K: 28, L: 5, Precision:0.7882882882882883\n",
      "K: 28, L: 6, Precision:0.8378378378378378\n",
      "K: 28, L: 7, Precision:0.8513513513513513\n",
      "K: 28, L: 8, Precision:0.8671171171171171\n",
      "K: 28, L: 9, Precision:0.9211711711711712\n",
      "K: 28, L: 10, Precision:0.9234234234234234\n",
      "K: 29, L: 1, Precision:0.4144144144144144\n",
      "K: 29, L: 2, Precision:0.5833333333333334\n",
      "K: 29, L: 3, Precision:0.7027027027027027\n",
      "K: 29, L: 4, Precision:0.7364864864864865\n",
      "K: 29, L: 5, Precision:0.8085585585585585\n",
      "K: 29, L: 6, Precision:0.8288288288288288\n",
      "K: 29, L: 7, Precision:0.8490990990990991\n",
      "K: 29, L: 8, Precision:0.8941441441441441\n",
      "K: 29, L: 9, Precision:0.8851351351351351\n",
      "K: 29, L: 10, Precision:0.8806306306306306\n",
      "K: 30, L: 1, Precision:0.36036036036036034\n",
      "K: 30, L: 2, Precision:0.5990990990990991\n",
      "K: 30, L: 3, Precision:0.6328828828828829\n",
      "K: 30, L: 4, Precision:0.7702702702702703\n",
      "K: 30, L: 5, Precision:0.8085585585585585\n",
      "K: 30, L: 6, Precision:0.8153153153153153\n",
      "K: 30, L: 7, Precision:0.8445945945945946\n",
      "K: 30, L: 8, Precision:0.8423423423423423\n",
      "K: 30, L: 9, Precision:0.8716216216216216\n",
      "K: 30, L: 10, Precision:0.8693693693693694\n",
      "Max precision: 1.0, k: 7, L: 10\n"
     ]
    }
   ],
   "source": [
    "## Open dataset \n",
    "df = pd.read_csv('../../lsh-test-data/' + DATASET_NAME + '-embeddings.csv')\n",
    "\n",
    "## Remove 0 labled\n",
    "df = df[df.label == 1]\n",
    "\n",
    "precision_max = 0\n",
    "k_max = 0\n",
    "L_max = 0\n",
    "for k in range(30):\n",
    "    for L in range(10):\n",
    "        precision = performance_test(df, k + 1, L + 1, 150)\n",
    "        print(\"K: {0}, L: {1}, Precision:{2}\".format(k + 1, L + 1, precision))\n",
    "        if (precision >= precision_max):\n",
    "            precision_max = precision\n",
    "            k_max = k + 1\n",
    "            L_max = L + 1\n",
    "\n",
    "print(\"Max precision: {0}, k: {1}, L: {2}\".format(precision_max, k_max, L_max))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
